{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52aff0a",
   "metadata": {},
   "source": [
    "# TODO fase 1\n",
    " - calculate predictions for a stock fx apple\n",
    " - statistics for the predictions: distribution of errors, percentage prediction with the right direction:  close>open, open<close\n",
    " - visualize ohlc as bands and on stock curve\n",
    " - split in train, test so that test data are taken from time periodens after the training data and possibly from stocks that have not been used for training \n",
    "\n",
    " - tjek quantile objective function\n",
    " - objectiv function that weigh open and closing prices higher\n",
    "\n",
    " - add day of week to training data\n",
    "                                                                                                                 \n",
    "                                                                                                                 \n",
    "# TODO fase 2\n",
    " - language modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745b4d8",
   "metadata": {},
   "source": [
    "# DONE \n",
    " - speed up training: improve the pandas part by 30 to 60 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c3733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp finance.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3cd767",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55bdddce",
   "metadata": {},
   "source": [
    "#add the parent directiry so thatwecan access modules the and inits subdirectories\n",
    "import sys, os, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir  = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from lib.data.lists import *\n",
    "from lib.finance.data import *\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the main functionality from the SimFin Python API.\n",
    "import simfin as sf\n",
    "\n",
    "# Import names used for easy access to SimFin's data-columns.\n",
    "from simfin.names import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d1707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version of the SimFin Python API.\n",
    "sf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f76e5",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d438cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataPath:/Users/kasparlund/simfin_data exists:True\n",
      "Dataset \"us-shareprices-daily\" on disk (23 days old).\n",
      "- Loading from disk ... Done!\n",
      "number of stocks:         2615\n",
      "number of valid stocks:   2033\n",
      "number of invalid stocks: 582\n",
      "smallest pricelines pr stock: Ticker\n",
      "NLN      1\n",
      "WMG      2\n",
      "SSI     17\n",
      "GAMZ    18\n",
      "PCP     24\n",
      "dtype: int64\n",
      "longest pricelines pr stock:  Ticker\n",
      "HTH    3379\n",
      "HT     3379\n",
      "HSY    3379\n",
      "HST    3379\n",
      "KBR    3379\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_prices, stocks, validStocks, inValidStocks = prepareSimFinData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd208725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.452814e+06</td>\n",
       "      <td>5.452814e+06</td>\n",
       "      <td>5.452814e+06</td>\n",
       "      <td>5.452814e+06</td>\n",
       "      <td>5.452814e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.645078e+02</td>\n",
       "      <td>2.178618e-04</td>\n",
       "      <td>1.649711e-02</td>\n",
       "      <td>-1.613212e-02</td>\n",
       "      <td>5.501282e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.979344e+03</td>\n",
       "      <td>1.652678e-02</td>\n",
       "      <td>2.697750e-02</td>\n",
       "      <td>2.462773e-02</td>\n",
       "      <td>2.928071e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-4.800989e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02%</th>\n",
       "      <td>6.000000e-02</td>\n",
       "      <td>-2.137199e-01</td>\n",
       "      <td>-1.561031e-01</td>\n",
       "      <td>-3.292862e-01</td>\n",
       "      <td>-2.703173e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.520000e+01</td>\n",
       "      <td>-3.935865e-03</td>\n",
       "      <td>3.807107e-03</td>\n",
       "      <td>-2.225379e-02</td>\n",
       "      <td>-1.051304e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.957000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.079417e-02</td>\n",
       "      <td>-1.064184e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.393000e+01</td>\n",
       "      <td>4.559025e-03</td>\n",
       "      <td>2.192243e-02</td>\n",
       "      <td>-3.395201e-03</td>\n",
       "      <td>1.118881e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.98%</th>\n",
       "      <td>2.162699e+05</td>\n",
       "      <td>2.282198e-01</td>\n",
       "      <td>4.400000e-01</td>\n",
       "      <td>1.520392e-01</td>\n",
       "      <td>3.332735e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.449700e+05</td>\n",
       "      <td>1.407407e+00</td>\n",
       "      <td>1.477419e+00</td>\n",
       "      <td>1.210095e+00</td>\n",
       "      <td>1.421652e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_close          Open          High           Low         Close\n",
       "count     5.452814e+06  5.452814e+06  5.452814e+06  5.452814e+06  5.452814e+06\n",
       "mean      1.645078e+02  2.178618e-04  1.649711e-02 -1.613212e-02  5.501282e-04\n",
       "std       4.979344e+03  1.652678e-02  2.697750e-02  2.462773e-02  2.928071e-02\n",
       "min       2.000000e-02 -5.000000e-01 -4.800989e-01 -5.000000e-01 -5.000000e-01\n",
       "0.02%     6.000000e-02 -2.137199e-01 -1.561031e-01 -3.292862e-01 -2.703173e-01\n",
       "25%       1.520000e+01 -3.935865e-03  3.807107e-03 -2.225379e-02 -1.051304e-02\n",
       "50%       2.957000e+01  0.000000e+00  1.079417e-02 -1.064184e-02  0.000000e+00\n",
       "75%       5.393000e+01  4.559025e-03  2.192243e-02 -3.395201e-03  1.118881e-02\n",
       "99.98%    2.162699e+05  2.282198e-01  4.400000e-01  1.520392e-01  3.332735e-01\n",
       "max       3.449700e+05  1.407407e+00  1.477419e+00  1.210095e+00  1.421652e+00"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistics on the mature stocks\n",
    "df_prices.loc[validStocks,[PREV_CLOSE,OPEN,HIGH,LOW,CLOSE]].describe(percentiles=[0.0002, 0.25, 0.75, 0.9998])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization_faktor = 2.697750e-02\n",
    "#TODO add normalized datacolumn to df_prices indstead of replacing them\n",
    "normalized_prefix=\"normalized_\"\n",
    "[NORM_OPEN,NORM_HIGH,NORM_LOW,NORM_CLOSE] = [normalized_prefix+OPEN,\\\n",
    "                                             normalized_prefix+HIGH,\\\n",
    "                                             normalized_prefix+LOW,\\\n",
    "                                             normalized_prefix+CLOSE]\n",
    "\n",
    "#use tanh to squeez the data range\n",
    "def normalizeData( df_prices, columns, normalization_faktor=2.7e-02, normalized_prefix=normalized_prefix):\n",
    "    #normalize the training data\n",
    "    if not normalization_faktor==1.0 :\n",
    "        normalized_columns = [\"normalized_\"+ name for name in columns]\n",
    "        #df_prices[normalized_columns] = np.tanh(8*df_prices[columns].values)\n",
    "        df_prices[normalized_columns] = np.tanh(14*np.log1p(df_prices[columns].values))\n",
    "    return df_prices,normalized_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class OHLCDatasetClose(OHLCDataset):\n",
    "    #x, y significes input vs output\n",
    "    def __init__(self, df_prices, stocks, column_names, seq_length): \n",
    "        super().__init__(df_prices, stocks, column_names, seq_length)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        ix = self.idx_seq[index,:]        \n",
    "        pi = torch.tensor( self.np_prices[ix[1]:ix[0]] )\n",
    "        pt = torch.tensor( self.np_prices[ix[0]:ix[0]+1] )\n",
    "        return pi, pt #, index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb1506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training columns = ['normalized_Open', 'normalized_Close']\n",
      "number of stocks, train stocks, test stocks: 2033, 1525, 508\n",
      "CPU times: user 6.12 s, sys: 1.42 s, total: 7.54 s\n",
      "Wall time: 7.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from lib.learner.learner import*\n",
    "from lib.learner.optimizers import*\n",
    "from lib.model.model import*\n",
    "from lib.model.modelmanager import*\n",
    "import torch.nn as nn\n",
    "\n",
    "seq_length = 360 #\n",
    "#seq_length = 64\n",
    "#each priceline has 4 datapoint:[OPEN,LOW,HIGH,CLOSE]\n",
    "#batchsize is the number of stocks processed in parallel\n",
    "#seq_length is the number of input days og stock priced used to estimate the next days prices\n",
    "training_column_names = [OPEN,CLOSE]#[OPEN,HIGH,LOW,CLOSE] #[OPEN,#CLOSE]\n",
    "df_prices, training_column_names = normalizeData(df_prices,training_column_names)\n",
    "\n",
    "ohlc_ds = OHLCDatasetClose(df_prices, stocks=validStocks, column_names=training_column_names, seq_length=seq_length)\n",
    "ohlc_ds.initializeSquenzing()\n",
    "\n",
    "print(f\"training columns = {training_column_names}\")\n",
    ", \n",
    "train_ds, test_ds = ohlc_ds.split2train_test(0.25)\n",
    "print(f\"number of stocks, train stocks, test stocks: {len(ohlc_ds.stocks)}, {len(train_ds.stocks)}, {len(test_ds.stocks)}\")\n",
    "\n",
    "databunch = DataBunch(train_ds.dataloader(batch_size=2048, shuffle=True,  num_workers=0, drop_last=True), \\\n",
    "                      test_ds.dataloader( batch_size=4096, shuffle=False, num_workers=0, drop_last=False), \\\n",
    "                      c_in=len(ohlc_ds.column_names), c_out=len(ohlc_ds.column_names))\n",
    "\n",
    "#batch = next(iter(databunch.train_dl))\n",
    "#batch[0].dtype, batch[0].shape, view(batch[0]).shape\n",
    "\n",
    "\n",
    "#print(\"the following lengths must be the same\")\n",
    "#%time stock_days = [len(ohlc_ds.stock_grps.get_group(stock)) for stock in ohlc_ds.stocks]\n",
    "#print(len(ohlc_ds), sum(stock_days)-len(stock_days)*(seq_length+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488077f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 3 s, total: 1min 12s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%time l = [len(b[0]) for b in databunch.train_dl]\n",
    "del l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2ea6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2048, 720]), torch.Size([2048, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(databunch.train_dl))\n",
    "batch[0].shape,batch[1].shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85efaeee",
   "metadata": {},
   "source": [
    "#import scipy.special\n",
    "#from bokeh.layouts import gridplot\n",
    "#from bokeh.plotting import figure, show\n",
    "from lib.finance.graphs import *\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "\n",
    "data_column = training_column_names[0]\n",
    "stocks      = ohlc_ds.stocks\n",
    "df_select   = df_prices.loc[stocks,data_column]\n",
    "measured    = df_select.values\n",
    "x           = np.linspace(-measured.min(), measured.max(), 100)\n",
    "hist, edges = np.histogram(measured, density=True, bins=100)\n",
    "#df[training_column_names].to_numpy()[:,0],\n",
    "# Add normal Distribution\n",
    "#x = np.linspace(-2, 2, 1000)\n",
    "#pdf = 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "#cdf = (1+scipy.special.erf((x-mu)/np.sqrt(2*sigma**2)))/2\n",
    "\n",
    "p1 = make_plot(\"Histogram for \"+data_column, hist, edges, x)\n",
    "show(gridplot([p1], ncols=1, plot_width=1000, plot_height=400))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095578f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from lib.model.model import *\n",
    "from functools import reduce\n",
    "\n",
    "#torch.nn.Tanh(), torch.nn.ReLU(inplace=False), #     torch.nn.Tanh(), #nn.LeakyReLU(inplace=True), #\n",
    "class Block(nn.Sequential):\n",
    "    def __init__(self, in_dim, width, activ_func=torch.nn.Tanh(), dropout_ratio=0.0):\n",
    "        super().__init__(\n",
    "                            torch.nn.BatchNorm1d(1),\n",
    "                            activ_func,\n",
    "                            nn.Dropout(p=dropout_ratio, inplace=False),\n",
    "                            nn.Linear(in_dim,width),\n",
    "                          \n",
    "                            torch.nn.BatchNorm1d(1),\n",
    "                            nn.Dropout(p=dropout_ratio, inplace=False),\n",
    "                            activ_func,\n",
    "                            nn.Linear(width,in_dim),\n",
    "                            )\n",
    "        \n",
    "class DenseResBlock(nn.Module):\n",
    "    def __init__(self, in_dim, widths, activ_func=torch.nn.Tanh(), dropout_ratio=0.0):\n",
    "        super().__init__()\n",
    "        #widths = [int(in_dim/16+0.5), int(in_dim/8+0.5), int(in_dim/4+0.5), int(in_dim/2+0.5), in_dim]\n",
    "        self.block_1 = Block(in_dim, widths[0], activ_func, dropout_ratio)\n",
    "    def forward(self,x):\n",
    "        #return self.block_1(x)+self.block_2(x)+self.block_3(x)\n",
    "        return self.block_1(x)\n",
    "\n",
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, seq_length, embedding_width, res_in_dim, activ_func=torch.nn.Tanh(), dropout_ratio=0.0 ):\n",
    "        super().__init__(\n",
    "                        nn.Linear(seq_length,embedding_width),\n",
    "    \n",
    "                        torch.nn.BatchNorm1d(1),\n",
    "                        nn.Dropout(p=dropout_ratio, inplace=False),\n",
    "                        activ_func, \n",
    "                        nn.Linear(embedding_width,embedding_width),\n",
    "    \n",
    "                        torch.nn.BatchNorm1d(1),\n",
    "                        nn.Dropout(p=dropout_ratio, inplace=False),\n",
    "                        activ_func, \n",
    "                        nn.Linear(embedding_width,res_in_dim)\n",
    "            )\n",
    "    \n",
    "from functools import reduce\n",
    "class DenseResNetModel(nn.Module):\n",
    "    def __init__(self, nb_stems, seq_length, embedding_width, nb_res, res_in_dim, res_block_widths=[], activ_func=torch.nn.Tanh(), dropout_ratio=0.0 ):\n",
    "        super().__init__()\n",
    "        self.stems = nn.ModuleList()\n",
    "        for i in range(nb_stems):\n",
    "            self.stems.append(Stem(seq_length, embedding_width, res_in_dim, activ_func, dropout_ratio))\n",
    "            \n",
    "        blocks = [DenseResBlock(res_in_dim, res_block_widths, activ_func, dropout_ratio) \n",
    "                  for i in np.arange(nb_res)]\n",
    "        self.resblocks = nn.Sequential(*blocks)\n",
    "    \n",
    "        self.fadeout = nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(1),\n",
    "            activ_func,\n",
    "    \n",
    "            nn.Linear(in_dim,1),\n",
    "            nn.Flatten()\n",
    "            )\n",
    "\n",
    "    \"\"\"    \n",
    "    def forward(self,x):\n",
    "        x_stems     = [s(x) for s in self.stems]\n",
    "        x_stem      = reduce(lambda a, b: a + b, x_stems )\n",
    "        x_resblocks = self.resblocks(x_stem)\n",
    "        x_fadeout   = self.fadeout(x_resblocks)        return x_fadeout \n",
    "    \n",
    "    \"\"\"\n",
    "    # fast and consumes less memeory comparede to the reduce and comprehension version\n",
    "    def forward(self,x):\n",
    "        x_stem = self.stems[0](x)\n",
    "        for stem in self.stems[1:]: x_stem = x_stem+stem(x)\n",
    "            \n",
    "        x_resblocks = self.resblocks(x_stem)\n",
    "        x_fadeout   = self.fadeout(x_resblocks)\n",
    "        return x_fadeout         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af07522",
   "metadata": {},
   "source": [
    "# We start by a regressionmodel that predict the next OHLC\n",
    " - First try will be the to minimize the squared sum of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c32866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_of_batchsamples:720\n"
     ]
    }
   ],
   "source": [
    "def my_mse_loss(estimate, target): \n",
    "    return (estimate-target).square().mean()\n",
    "def accuracy_sign(estimate, target): \n",
    "    return (torch.sgn(estimate).eq(torch.sgn(target))).float().mean()\n",
    "    #return (torch.sgn(estimate[:,0]).eq(torch.sgn(target[:,0]))).float().mean()\n",
    "\n",
    "len_of_batchsamples = seq_length*len(training_column_names)\n",
    "print(f\"len_of_batchsamples:{len_of_batchsamples}\")\n",
    "tensor_input_view = view_tfm(1,len_of_batchsamples)\n",
    "\n",
    "sched        = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)]) \n",
    "cbfs         = [TrainableModelCallback, TrainEvalCallback, OptimizerCallback, \n",
    "                partial(BatchTransformXCallback, tfm = tensor_input_view), \n",
    "                Recorder, \n",
    "                partial(AvgStatsCallback,[accuracy_sign]),\n",
    "                ProgressCallback\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#widths = [int(in_dim/4+0.5), int(in_dim/2+0.5), in_dim, 2*in_dim]\n",
    "#widths = [int(in_dim/16+0.5), int(in_dim/8+0.5), int(in_dim/4+0.5), int(in_dim/2+0.5), in_dim]\n",
    "#widths = [in_dim, in_dim, in_dim, in_dim, in_dim]\n",
    "#widths = [int(in_dim/8+0.5), int(in_dim/4+0.5), int(in_dim/2+0.5), in_dim]\n",
    "embedding_width = 300  \n",
    "in_dim = embedding_tail  = 32\n",
    "nb_stems=5\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "#activ_func=torch.nn.Tanh(inplace=False)\n",
    "activ_func=torch.nn.ReLU(inplace=True)\n",
    "model = DenseResNetModel(nb_stems, len_of_batchsamples, embedding_width, nb_res, embedding_tail, widths, \n",
    "                         activ_func=activ_func, dropout_ratio=dropout_ratio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f3d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f82068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:torch.Size([2048, 1, 720])\n",
      "<class '__main__.DenseResNetModel'> torch.Size([2048, 1])\n",
      "CPU times: user 1.57 s, sys: 209 ms, total: 1.78 s\n",
      "Wall time: 691 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#layer = partial( conv_layer1, stride=1, bn=False, zero_bn=False, act=partial(GeneralRelu,leak=0.01), dropout_ratio=0.15 )\n",
    "#layer = partial( conv_layer1, stride=1, bn=False, zero_bn=False, act=GeneralRelu, dropout_ratio=0)#dropout_ratio=0.15 )\n",
    "#mm    = CnnModelManager( get_cnn_model1(layers_sizes, databunch.c_in, databunch.c_out, layer ) )\n",
    "\n",
    "mm    = CnnModelManager( model )\n",
    "#mm.initialize(nonlinearity=\"relu\") #initialize=relu, leaky_relu, tanh, selu\n",
    "\n",
    "xb,_ = mm.getFirstbatch( databunch, normalization = tensor_input_view)\n",
    "print(f\"input shape:{xb.shape}\")\n",
    "mm.summary(xb, print_mod=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ohlc_ds.df_prices.columns, ohlc_ds.df_prices[\"normalized_Close\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17cab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ds.idx_seq[:10], train_ds.df_prices.shape, train_ds.np_prices.shape, train_ds.np_prices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5479f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy_sign</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy_sign</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>0.556255</td>\n",
       "      <td>0.022873</td>\n",
       "      <td>0.559878</td>\n",
       "      <td>13:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47min 25s, sys: 4min 47s, total: 52min 13s\n",
      "Wall time: 13min 28s\n"
     ]
    }
   ],
   "source": [
    "#opt       = SGD(sched,max_lr=0.1)\n",
    "#opt       = Adam(sched,max_lr=5e-3, moms=(0.85,0.95), max_wd = 0)#1e-5)#1e-6)\n",
    "opt       = Adam(sched,max_lr=1e-2, moms=(0.85,0.95), max_wd = 1e-5)#)#1e-6)\n",
    "loss_func = torch.nn.MSELoss() #torch.nn.SmoothL1Loss(), my_mse_loss #nn.L1Loss()\n",
    "\n",
    "learn = Learner( mm.model, databunch, loss_func=loss_func)\n",
    "%time learn.fit(3, opt=opt, cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1280bcd3",
   "metadata": {},
   "source": [
    "embedding_width = 300\n",
    "in_dim = embedding_tail  = 32\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "5 stems\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.026304\t0.501415\t0.022786\t0.559779\t11:59\n",
    "1\t0.022034\t0.584133\t0.020166\t0.619038\t11:28\n",
    "2\t0.020675\t0.612640\t0.019756\t0.634955\t11:35\n",
    "3\t0.020024\t0.623715\t0.019417\t0.632267\t11:35\n",
    "4\t0.019513\t0.631529\t0.019010\t0.647154\t11:37\n",
    "5\t0.019011\t0.638534\t0.018894\t0.651599\t11:39\n",
    "6\t0.018524\t0.643954\t0.018912\t0.655093\t11:35\n",
    "7\t0.018022\t0.648641\t0.018808\t0.654123\t11:37\n",
    "8\t0.017538\t0.653334\t0.018789\t0.656487\t11:34\n",
    "9\t0.017051\t0.656815\t0.018910\t0.661721\t11:35\n",
    "10\t0.016581\t0.660552\t0.018875\t0.660443\t11:37\n",
    "11\t0.016142\t0.663426\t0.018990\t0.653821\t11:32\n",
    "12\t0.015704\t0.666320\t0.018962\t0.663851\t11:32\n",
    "13\t0.015397\t0.668422\t0.018950\t0.663851\t11:29\n",
    "14\t0.015103\t0.670594\t0.019062\t0.664678\t11:34\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.015549\t0.666702\t0.019057\t0.658016\t12:11\n",
    "1\t0.016501\t0.659836\t0.019020\t0.657670\t11:34\n",
    "2\t0.016638\t0.659180\t0.019035\t0.661498\t21:11\n",
    "3\t0.016097\t0.663832\t0.019108\t0.665647\t12:19\n",
    "4\t0.015399\t0.668151\t0.018953\t0.663189\t13:17\n",
    "\n",
    "embedding_width = 300\n",
    "in_dim = embedding_tail  = 32\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "5 stems\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.025831\t0.509928\t0.022637\t0.575407\t11:59\n",
    "1\t0.021649\t0.591471\t0.019711\t0.630737\t11:59\n",
    "2\t0.019789\t0.626395\t0.019287\t0.647498\t12:09\n",
    "\n",
    "\n",
    "embedding_width = 300\n",
    "in_dim = embedding_tail  = 32\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "3 stems\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.026388\t0.497873\t0.023428\t0.489625\t08:04\n",
    "1\t0.022215\t0.551736\t0.021085\t0.527333\t08:03\n",
    "2\t0.020432\t0.587045\t0.019779\t0.584114\t08:20\n",
    "\n",
    "\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.025228\t0.512751\t0.024461\t0.573977\t08:40\n",
    "1\t0.021389\t0.586013\t0.021571\t0.619176\t09:22\n",
    "2\t0.019735\t0.618006\t0.020761\t0.640264\t08:45\n",
    "med close,open\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.052860\t0.496458\t0.049194\t0.529433\t10:03\n",
    "1\t0.046402\t0.537989\t0.045046\t0.565951\t09:02\n",
    "2\t0.043468\t0.560542\t0.043630\t0.552125\t08:38\n",
    "\n",
    "embedding_width = 200  \n",
    "in_dim = embedding_tail  = 64\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.025149\t0.512019\t0.023626\t0.559002\t08:43\n",
    "1\t0.021199\t0.573458\t0.021753\t0.603393\t08:42\n",
    "2\t0.020187\t0.595626\t0.021375\t0.615417\t08:52\n",
    "3\t0.019678\t0.606731\t0.020966\t0.629788\t09:17\n",
    "4\t0.019222\t0.614983\t0.020771\t0.634349\t10:25\n",
    "5\t0.018793\t0.622499\t0.020551\t0.616955\t09:38\n",
    "6\t0.018379\t0.628418\t0.020306\t0.645403\t10:00\n",
    "7\t0.017990\t0.633293\t0.020205\t0.644536\t10:04\n",
    "8\t0.017616\t0.637786\t0.020090\t0.650745\t09:26\n",
    "9\t0.017218\t0.641595\t0.020108\t0.651130\t09:56\n",
    "10\t0.016855\t0.645587\t0.020369\t0.636307\t09:56\n",
    "11\t0.016472\t0.647683\t0.020122\t0.652227\t09:03\n",
    "12\t0.016154\t0.650732\t0.020049\t0.654212\t09:21\n",
    "13\t0.015866\t0.652455\t0.020006\t0.653716\t09:15\n",
    "14\t0.015631\t0.654128\t0.020066\t0.652828\t08:43\n",
    "CPU times: user 8h 28min 28s, sys: 40min 41s, total: 9h 9min 9s\n",
    "Wall time: 2h 21min 27s\n",
    "\n",
    "\n",
    "embedding_width = 200\n",
    "in_dim = embedding_tail  = 32\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "5 stems\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.025228\t0.512751\t0.024461\t0.573977\t08:40\n",
    "1\t0.021389\t0.586013\t0.021571\t0.619176\t09:22\n",
    "2\t0.019735\t0.618006\t0.020761\t0.640264\t08:45\n",
    "\n",
    "embedding_width = 200\n",
    "in_dim = embedding_tail  = 32\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "3 stems\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.025909\t0.493829\t0.025377\t0.466628\t06:18\n",
    "1\t0.021877\t0.550566\t0.022160\t0.591280\t06:16\n",
    "2\t0.020273\t0.585149\t0.021436\t0.615480\t06:18\n",
    "\n",
    "\n",
    "embedding_width = 300\n",
    "in_dim = embedding_tail  = 32\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "3 stems\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.025747\t0.501087\t0.024687\t0.556145\t08:15\n",
    "1\t0.021631\t0.572095\t0.021908\t0.612805\t08:05\n",
    "2\t0.019952\t0.610323\t0.021250\t0.631169\t08:14\n",
    "\n",
    "\n",
    "embedding_width = 300\n",
    "in_dim = embedding_tail  = 32\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "1 stems\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.025901\t0.498152\t0.024129\t0.548389\t04:32\n",
    "1\t0.021780\t0.561339\t0.021956\t0.599828\t04:25\n",
    "2\t0.020433\t0.590841\t0.021675\t0.610472\t04:17\n",
    "\n",
    "\n",
    "embedding_width = 300  \n",
    "in_dim = embedding_tail  = 64\n",
    "nb_res = 2\n",
    "dropout_ratio=0.3\n",
    "widths = [in_dim]\n",
    "one stem\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.026119\t0.509259\t0.022139\t0.547328\t04:40\n",
    "1\t0.022578\t0.557341\t0.020687\t0.592888\t04:39\n",
    "2\t0.021614\t0.576584\t0.020087\t0.601353\t04:21\n",
    "3\t0.021169\t0.585959\t0.019783\t0.601742\t04:15\n",
    "4\t0.020813\t0.592921\t0.019441\t0.610521\t04:17\n",
    "5\t0.020473\t0.598384\t0.019125\t0.605935\t04:16\n",
    "6\t0.020167\t0.603306\t0.019079\t0.626156\t04:16\n",
    "7\t0.019888\t0.607462\t0.018922\t0.623386\t04:17\n",
    "8\t0.019641\t0.611657\t0.018883\t0.616920\t04:18\n",
    "9\t0.019369\t0.614790\t0.018784\t0.625805\t04:16\n",
    "10\t0.019133\t0.617742\t0.018704\t0.628645\t04:19\n",
    "11\t0.018902\t0.619259\t0.018828\t0.625192\t04:15\n",
    "12\t0.018690\t0.621203\t0.018761\t0.635828\t04:16\n",
    "13\t0.018522\t0.623104\t0.018710\t0.634989\t04:16\n",
    "14\t0.018368\t0.623672\t0.018818\t0.623181\t04:15"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03979f08",
   "metadata": {},
   "source": [
    "epochs = 3\n",
    "opt       = Adam(sched,max_lr=1e-2, moms=(0.85,0.95), max_wd = 1e-5)#)#1e-6)\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.072175\t0.566837\t0.070174\t0.588738\t05:25\n",
    "1\t0.070976\t0.575896\t0.069200\t0.596989\t05:15\n",
    "2\t0.068451\t0.589934\t0.067226\t0.606293\t05:16\n",
    "\n",
    "epochs=1\n",
    "dropout before all active_func\n",
    "dropout_ratio=0.3\n",
    "nn.Dropout(p=dropout_ratio, inplace=True),\n",
    "activ_func, #torch.nn.ReLU(inplace=True),\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.061389\t0.618179\t0.066129\t0.620776\t05:15\n",
    "\n",
    "epochs=30\n",
    "dropout before all active_func\n",
    "dropout_ratio=0.3\n",
    "nn.Dropout(p=dropout_ratio, inplace=True),\n",
    "activ_func, #torch.nn.ReLU(inplace=True),\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.082902\t0.508284\t0.076751\t0.541714\t05:27\n",
    "1\t0.075270\t0.547605\t0.071427\t0.577500\t05:17\n",
    "2\t0.072053\t0.569577\t0.069564\t0.592215\t04:58\n",
    "3\t0.070436\t0.580453\t0.068490\t0.599483\t05:07\n",
    "4\t0.069484\t0.587298\t0.067915\t0.600083\t05:20\n",
    "5\t0.068803\t0.590994\t0.067668\t0.605923\t05:02\n",
    "6\t0.068235\t0.593722\t0.067119\t0.597811\t04:52\n",
    "7\t0.067670\t0.596932\t0.066765\t0.612469\t04:49\n",
    "8\t0.067139\t0.600273\t0.066717\t0.613111\t04:45\n",
    "9\t0.066608\t0.602197\t0.066339\t0.615885\t04:44\n",
    "10\t0.066151\t0.604375\t0.066183\t0.609146\t04:44\n",
    "11\t0.065699\t0.606015\t0.066580\t0.607388\t04:47\n",
    "12\t0.065144\t0.607875\t0.066323\t0.604254\t04:49\n",
    "13\t0.064805\t0.610046\t0.065563\t0.621428\t04:48\n",
    "14\t0.064363\t0.611827\t0.066211\t0.621515\t04:48\n",
    "15\t0.063981\t0.612619\t0.065615\t0.621399\t05:29\n",
    "16\t0.063576\t0.614445\t0.065922\t0.608415\t05:25\n",
    "17\t0.063279\t0.615262\t0.065736\t0.610579\t05:54\n",
    "18\t0.062833\t0.616602\t0.065756\t0.606987\t05:40\n",
    "19\t0.062490\t0.616651\t0.065739\t0.613158\t05:38\n",
    "20\t0.062171\t0.617527\t0.065599\t0.624231\t05:40\n",
    "21\t0.061817\t0.618802\t0.065663\t0.618451\t05:40\n",
    "22\t0.061474\t0.619992\t0.065622\t0.620450\t05:07\n",
    "23\t0.061153\t0.620087\t0.066041\t0.612405\t05:00\n",
    "24\t0.060883\t0.620478\t0.065873\t0.606467\t04:53\n",
    "25\t0.060600\t0.621460\t0.065731\t0.602982\t04:52\n",
    "26\t0.060317\t0.621599\t0.065580\t0.605186\t04:54\n",
    "27\t0.060088\t0.622396\t0.066005\t0.604864\t04:54\n",
    "28\t0.059903\t0.622715\t0.065836\t0.605811\t04:54\n",
    "29\t0.059683\t0.623256\t0.065990\t0.610759\t04:53\n",
    "\n",
    "\n",
    "epochs=30\n",
    "dropout at last part of stem and resblock \n",
    "dropout_ratio=0.5\n",
    "activ_func, #torch.nn.ReLU(inplace=False),\n",
    "nn.Dropout(p=dropout_ratio, inplace=True),\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.081568\t0.521587\t0.072495\t0.566318\t05:06\n",
    "1\t0.070989\t0.574966\t0.068640\t0.590897\t04:55\n",
    "2\t0.067046\t0.600585\t0.067139\t0.610124\t04:49\n",
    "3\t0.064731\t0.614119\t0.066489\t0.614196\t04:38\n",
    "4\t0.063172\t0.622318\t0.066127\t0.618571\t04:35\n",
    "5\t0.062008\t0.627647\t0.065977\t0.620419\t04:35\n",
    "6\t0.060943\t0.631609\t0.066315\t0.621868\t04:38\n",
    "7\t0.059977\t0.635247\t0.065970\t0.624276\t04:37\n",
    "8\t0.058928\t0.638965\t0.065893\t0.624368\t04:36\n",
    "9\t0.057851\t0.642442\t0.066477\t0.624215\t04:41\n",
    "10\t0.056847\t0.645738\t0.066083\t0.625458\t04:38\n",
    "11\t0.055960\t0.649088\t0.066935\t0.626083\t04:38\n",
    "12\t0.055113\t0.650986\t0.066667\t0.626675\t04:38\n",
    "13\t0.054281\t0.653652\t0.067271\t0.626913\t04:38\n",
    "14\t0.053506\t0.655786\t0.067558\t0.627423\t04:39\n",
    "15\t0.052787\t0.657196\t0.068002\t0.626291\t04:40\n",
    "16\t0.052121\t0.659180\t0.067960\t0.627112\t04:40\n",
    "17\t0.051409\t0.660631\t0.069259\t0.627039\t04:37\n",
    "18\t0.050793\t0.662709\t0.068972\t0.626539\t04:38\n",
    "19\t0.050133\t0.664221\t0.069420\t0.625826\t04:39\n",
    "20\t0.049532\t0.665437\t0.069646\t0.625871\t04:39\n",
    "21\t0.048940\t0.667061\t0.070622\t0.624804\t04:39\n",
    "22\t0.048398\t0.667747\t0.071460\t0.623973\t04:38\n",
    "23\t0.047852\t0.668795\t0.071687\t0.623899\t04:38\n",
    "24\t0.047347\t0.669892\t0.071887\t0.623731\t04:39\n",
    "25\t0.046882\t0.670719\t0.072265\t0.622776\t04:39\n",
    "26\t0.046503\t0.671618\t0.072090\t0.622318\t04:37\n",
    "27\t0.046128\t0.672350\t0.072190\t0.621886\t04:38\n",
    "28\t0.045855\t0.672726\t0.071920\t0.622085\t04:34\n",
    "29\t0.045621\t0.673157\t0.072791\t0.621886\t04:40\n",
    "\n",
    "\n",
    "epochs=30\n",
    "after all active_func\n",
    "dropout_ratio=0.5\n",
    "activ_func, #torch.nn.ReLU(inplace=False),\n",
    "nn.Dropout(p=dropout_ratio, inplace=True),\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.085182\t0.493225\t0.082285\t0.495261\t05:39\n",
    "1\t0.081452\t0.504149\t0.079681\t0.513394\t05:30\n",
    "2\t0.079811\t0.522061\t0.077722\t0.542383\t05:20\n",
    "3\t0.077795\t0.550383\t0.072781\t0.580662\t05:17\n",
    "4\t0.075600\t0.565415\t0.071311\t0.594237\t05:09\n",
    "5\t0.074427\t0.570124\t0.069735\t0.599682\t05:02\n",
    "6\t0.073778\t0.572630\t0.068326\t0.601706\t04:59\n",
    "7\t0.073247\t0.573970\t0.068812\t0.600359\t05:01\n",
    "8\t0.072858\t0.575802\t0.070522\t0.571898\t05:02\n",
    "9\t0.072493\t0.576827\t0.068152\t0.607145\t05:04\n",
    "10\t0.072105\t0.577709\t0.069403\t0.600371\t05:04\n",
    "11\t0.071798\t0.578961\t0.067778\t0.603549\t05:07\n",
    "12\t0.071487\t0.579563\t0.069876\t0.601706\t04:52\n",
    "13\t0.071164\t0.581017\t0.068926\t0.604608\t04:58\n",
    "14\t0.070878\t0.580963\t0.068652\t0.609540\t05:02\n",
    "15\t0.070407\t0.580676\t0.067865\t0.609023\t05:09\n",
    "16\t0.069989\t0.581453\t0.067723\t0.607632\t05:21\n",
    "17\t0.069650\t0.581887\t0.067662\t0.610676\t05:48\n",
    "18\t0.069393\t0.582225\t0.067849\t0.595511\t05:14\n",
    "19\t0.069091\t0.583649\t0.067747\t0.593705\t05:09\n",
    "20\t0.068918\t0.584695\t0.067457\t0.609967\t05:09\n",
    "21\t0.068685\t0.585203\t0.068101\t0.612315\t04:59\n",
    "22\t0.068470\t0.585334\t0.067646\t0.600884\t05:02\n",
    "23\t0.068284\t0.586689\t0.067324\t0.610421\t05:05\n",
    "24\t0.068128\t0.586833\t0.067446\t0.603262\t05:17\n",
    "25\t0.067875\t0.587770\t0.067362\t0.602046\t05:15\n",
    "26\t0.067734\t0.587914\t0.067208\t0.601931\t05:13\n",
    "27\t0.067579\t0.588928\t0.067448\t0.603889\t05:20\n",
    "28\t0.067479\t0.588909\t0.067492\t0.606761\t05:36\n",
    "29\t0.067324\t0.589053\t0.067305\t0.605655\t05:30\n",
    "\n",
    "epochs=30\n",
    "after all active_func\n",
    "dropout_ratio=0.2\n",
    "activ_func, #torch.nn.ReLU(inplace=False),\n",
    "nn.Dropout(p=dropout_ratio, inplace=True),\n",
    "5 stems and 1 block\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.080934\t0.518930\t0.076364\t0.559751\t06:06\n",
    "1\t0.071644\t0.566792\t0.071782\t0.586702\t06:25\n",
    "2\t0.068490\t0.587469\t0.069798\t0.603280\t06:01\n",
    "3\t0.066871\t0.596950\t0.069168\t0.606126\t05:15\n",
    "4\t0.065860\t0.602218\t0.068651\t0.612136\t05:12\n",
    "5\t0.065120\t0.605071\t0.068250\t0.611442\t05:12\n",
    "6\t0.064478\t0.607887\t0.068134\t0.608562\t05:11\n",
    "7\t0.063902\t0.610331\t0.067997\t0.611858\t05:13\n",
    "8\t0.063309\t0.612696\t0.067575\t0.616280\t05:12\n",
    "9\t0.062700\t0.614808\t0.067514\t0.620344\t05:13\n",
    "10\t0.062114\t0.617200\t0.067355\t0.619720\t05:13\n",
    "11\t0.061578\t0.619078\t0.067333\t0.620024\t05:11\n",
    "12\t0.061004\t0.621522\t0.067418\t0.623230\t05:15\n",
    "13\t0.060555\t0.623040\t0.067353\t0.622234\t05:12\n",
    "14\t0.060116\t0.624036\t0.067448\t0.617525\t05:11\n",
    "15\t0.059637\t0.626159\t0.067241\t0.617923\t05:14\n",
    "16\t0.059208\t0.627379\t0.067498\t0.621651\t05:13\n",
    "17\t0.058815\t0.628358\t0.067748\t0.622507\t05:13\n",
    "18\t0.058351\t0.629319\t0.067537\t0.624094\t05:13\n",
    "19\t0.057894\t0.631374\t0.067618\t0.620491\t05:12\n",
    "20\t0.057525\t0.632479\t0.067687\t0.624436\t05:13\n",
    "21\t0.057109\t0.633252\t0.067894\t0.624035\t05:13\n",
    "22\t0.056707\t0.634319\t0.067782\t0.623225\t06:08\n",
    "23\t0.056341\t0.635762\t0.067898\t0.621900\t05:35\n",
    "24\t0.056006\t0.636483\t0.067828\t0.624041\t05:42\n",
    "25\t0.055683\t0.637114\t0.068198\t0.623394\t05:37\n",
    "26\t0.055367\t0.638397\t0.068633\t0.611663\t06:04\n",
    "27\t0.055140\t0.638525\t0.068407\t0.607513\t05:40\n",
    "28\t0.054936\t0.639241\t0.068325\t0.621952\t05:58\n",
    "29\t0.054778\t0.639599\t0.068357\t0.619476\t06:20"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9994d23",
   "metadata": {},
   "source": [
    "epochs=10\n",
    " \n",
    "after all active_func\n",
    "dropout_ratio=0.2\n",
    "activ_func, #torch.nn.ReLU(inplace=False),\n",
    "nn.Dropout(p=dropout_ratio, inplace=True),\n",
    "nn.Linear(stem2_embedding_width,stem2_embedding_width),\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.080722\t0.518781\t0.076335\t0.557329\t07:01\n",
    "1\t0.071937\t0.562651\t0.072346\t0.586225\t06:44\n",
    "2\t0.069052\t0.580626\t0.070607\t0.598413\t05:17\n",
    "3\t0.067124\t0.590751\t0.069504\t0.599598\t05:20\n",
    "4\t0.065476\t0.599937\t0.068281\t0.609511\t05:53\n",
    "5\t0.064030\t0.606920\t0.067823\t0.607450\t06:51\n",
    "6\t0.062637\t0.612632\t0.067273\t0.619010\t05:32\n",
    "7\t0.061378\t0.617884\t0.067310\t0.616013\t05:12\n",
    "8\t0.060245\t0.621344\t0.067274\t0.620901\t05:14\n",
    "9\t0.059429\t0.624262\t0.067463\t0.618768\t05:15\n",
    "\n",
    "dropout_ratio=0.2\n",
    "torch.nn.BatchNorm1d(1),\n",
    "nn.Dropout(p=dropout_ratio, inplace=True),\n",
    "activ_func, #torch.nn.ReLU(inplace=False), \n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.078652\t0.531649\t0.074328\t0.565944\t06:15\n",
    "1\t0.069978\t0.579208\t0.071753\t0.574019\t06:05\n",
    "2\t0.067294\t0.597092\t0.069559\t0.601312\t04:58\n",
    "3\t0.065320\t0.608653\t0.068054\t0.615492\t05:18\n",
    "4\t0.063633\t0.616797\t0.067559\t0.619736\t05:35\n",
    "5\t0.062107\t0.623397\t0.066813\t0.622815\t06:10\n",
    "6\t0.060749\t0.629121\t0.066676\t0.625658\t06:30\n",
    "7\t0.059403\t0.634373\t0.066499\t0.624043\t05:30\n",
    "8\t0.058237\t0.637944\t0.066564\t0.627859\t04:55\n",
    "9\t0.057389\t0.641333\t0.067027\t0.626473\t04:55\n",
    "\n",
    "\n",
    "only after the last active_func\n",
    "dropout_ratio=0.2\n",
    "activ_func, #torch.nn.ReLU(inplace=False),\n",
    "nn.Dropout(p=dropout_ratio, inplace=True),\n",
    "nn.Linear(stem2_embedding_width,stem2_embedding_width),\n",
    "epoch\ttrain_loss\ttrain_accuracy_sign\tvalid_loss\tvalid_accuracy_sign\ttime\n",
    "0\t0.076932\t0.539153\t0.073102\t0.580332\t05:57\n",
    "1\t0.068160\t0.589681\t0.070588\t0.596225\t05:41\n",
    "2\t0.065297\t0.608026\t0.068710\t0.609857\t04:51\n",
    "3\t0.062843\t0.620163\t0.067861\t0.617189\t04:52\n",
    "4\t0.060457\t0.631495\t0.067699\t0.621257\t04:49\n",
    "5\t0.058214\t0.639709\t0.067412\t0.623525\t04:51\n",
    "6\t0.056022\t0.646931\t0.067838\t0.627729\t04:47\n",
    "7\t0.053956\t0.653144\t0.068241\t0.628750\t04:48\n",
    "8\t0.052164\t0.658577\t0.069615\t0.626556\t04:49\n",
    "9\t0.050855\t0.661623\t0.071031\t0.627836\t04:49\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792fb0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'plot_lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-14dad8939e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_subcription_by_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecorder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_subcription_by_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecorder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'plot_lr'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "learn.find_subcription_by_cls(Recorder).plot_lr(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_loss(skip_start=15),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "stocks = test_ds.stocks[:] #\"AAPL\"\n",
    "price_targets, prediction_columns = predict_stocks(test_ds, mm, stocks, tensor_input_view )\n",
    "price_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics on the columns and their predicted values\n",
    "columns = test_ds.column_names.copy()\n",
    "columns.extend(prediction_columns)\n",
    "print(columns)\n",
    "price_targets.loc[:,columns].describe(percentiles=[0.0002, 0.25, 0.75, 0.9998])        \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39b7ae3d",
   "metadata": {},
   "source": [
    "\tnormalized_Close\tpredict_normalized_Close\n",
    "count\t1.303303e+06\t1.303303e+06\n",
    "mean\t3.237851e-03\t3.665928e-03\n",
    "std\t    1.974514e-01\t7.889177e-02\n",
    "min\t   -9.992114e-01   -8.342363e-01\n",
    "0.02%  -9.750488e-01   -7.044529e-01\n",
    "25%\t   -8.545049e-02   -1.510273e-02\n",
    "50%\t    0.000000e+00\t2.520086e-03\n",
    "75%\t    9.036261e-02\t2.040304e-02\n",
    "99.98%\t9.912366e-01\t7.246236e-01\n",
    "max\t1.000000e+00\t8.689008e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot signal vs prediction\n",
    "#AAPL\n",
    "stock             = stocks[0]\n",
    "df                = price_targets.loc[stock].iloc[128:256] # extract a section\n",
    "training_column   = training_column_names[0]\n",
    "prediction_column = prediction_columns[0]\n",
    "\n",
    "reference_values  = df[training_column].to_numpy()\n",
    "prediction_values = df[prediction_column].to_numpy()\n",
    "dates             = np.arange(len(reference_values))\n",
    "same_sign         = np.sign(reference_values) == np.sign(prediction_values)\n",
    "\n",
    "reference_same_sign  = (reference_values[same_sign],  stock+\" reference\", \"blue\",  \"line\")\n",
    "prediction_same_sign = (prediction_values[same_sign], stock+\" prediction\",\"green\",\"circle\")\n",
    "#prediction_opposite_sign = (prediction_values[np.logical_not(same_sign)], stock+\" prediction\",\"red\",\"circle\")\n",
    "\n",
    "plotSignalVSPrediction(dates[same_sign],[reference_same_sign,prediction_same_sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[training_column_names].to_numpy()[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ac4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_targets.iloc[:10,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963344b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "normalization_faktor=2.7e-02\n",
    "print(sqrt(0.000250), 0.01**2) #0.000295\n",
    "print(sqrt(0.758663)*normalization_faktor, 0.01**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aebd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mm.model[0][0].weight\n",
    "#mm.model[0][0].bias"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e644662",
   "metadata": {},
   "source": [
    "#def my_mse_loss(t_in, t_target): return (t_in-t_target).square().mean()\n",
    "def accuracy_sign(out, yb): return (torch.sgn(out).eq(torch.sgn(yb))).float().mean()\n",
    "\n",
    "sched        = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)]) \n",
    "cbfs         = [TrainableModelCallback, TrainEvalCallback, OptimizerCallback, \n",
    "#                partial(CudaCallback, device= torch.device('cuda',0)),\n",
    "#                partial(ParamScheduler, 'lr', sched),\n",
    "                partial(BatchTransformXCallback, tfm = tensor_input_view), \n",
    "#                partial(MixUp,=0.4),\n",
    "#                LR_Finder,                \n",
    "                Recorder, \n",
    "#                partial(AvgStatsCallback,[accuracy]),\n",
    "#                partial(AvgStatsCallback,[my_mse_loss]),\n",
    "                partial(AvgStatsCallback,[torch.nn.functional.mse_loss,accuracy_sign]),\n",
    "#                partial(AvgStatsCallback,[torch.nn.functional.smooth_l1_loss]),\n",
    "                ProgressCallback\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
