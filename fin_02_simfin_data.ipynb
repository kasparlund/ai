{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87513f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp finance.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b50821",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c8a9a1b",
   "metadata": {},
   "source": [
    "#add the parent directiry so that wecan access modules the and inits subdirectories\n",
    "import sys, os, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir  = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from lib.data.lists import *\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the main functionality from the SimFin Python API.\n",
    "import simfin as sf\n",
    "\n",
    "# Import names used for easy access to SimFin's data-columns.\n",
    "from simfin.names import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0b1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version of the SimFin Python API.\n",
    "sf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e732be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def initiateSimFin(key='free'):\n",
    "    # SimFin data-directory.\n",
    "    sf.set_data_dir('~/simfin_data/')\n",
    "    # SimFin load API key or use free data.\n",
    "    sf.load_api_key(path='~/simfin_api_key.txt', default_key=key)\n",
    "    return Path.home()/\"simfin_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "#   extrem_increase,extrem__decrease = [], 2.5, -.73\n",
    "#   extrem_increase,extrem__decrease = [], 1.5, -.5\n",
    "EXTREM_HL = \"extrem_hl\"\n",
    "def flagstocks_extrem_hl(df_prices, extrem_increase, extrem__decrease):\n",
    "    #remove mature stocks with \"nan\" prices\n",
    "    if EXTREM_HL in df_prices.columns:\n",
    "        df_prices.drop(labels=EXTREM_HL,axis=1,inplace=True)\n",
    "\n",
    "    gt_p = df_prices[[HIGH]].gt(extrem_increase)\n",
    "    gt_p.insert(0,\"lt\",df_prices[[LOW]].lt(extrem__decrease))\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1,EXTREM_HL,gt_p.any(axis=1))\n",
    "    return df_prices\n",
    "\n",
    "TOO_FEW_DAYS = \"too_few_days\"\n",
    "def flagstocks_too_few_trading_days(df_prices, minimum_tradingdays):\n",
    "    grp_res = df_prices.groupby([\"Ticker\"]).apply(lambda group: len(group) < minimum_tradingdays)\n",
    "    grp_res.name = TOO_FEW_DAYS\n",
    "    merged = df_prices[[SIMFIN_ID]].join(grp_res, on=TICKER)\n",
    "    if TOO_FEW_DAYS in df_prices.columns:\n",
    "        df_prices.drop(labels=TOO_FEW_DAYS,axis=1,inplace=True)\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1, TOO_FEW_DAYS, merged[TOO_FEW_DAYS].values)\n",
    "    return df_prices\n",
    "\n",
    "HAS_NAN_DAYS = \"has_nan_days\"\n",
    "def flagstocks_with_nan_days(df_prices):\n",
    "    grp_res = df_prices.groupby([\"Ticker\"]).apply(lambda group: group[[OPEN,LOW,HIGH,CLOSE]].isnull().values.any() )\n",
    "    grp_res.name = HAS_NAN_DAYS\n",
    "    merged = df_prices[[SIMFIN_ID]].join(grp_res, on=TICKER)\n",
    "    if HAS_NAN_DAYS in df_prices.columns:\n",
    "        df_prices.drop(labels=HAS_NAN_DAYS,axis=1,inplace=True)\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1, HAS_NAN_DAYS, merged[HAS_NAN_DAYS].values)\n",
    "    return df_prices\n",
    "\n",
    "def findInValidStocks(df_prices):\n",
    "    flags  = [HAS_NAN_DAYS,TOO_FEW_DAYS,EXTREM_HL]\n",
    "    groups = df_prices.groupby([\"Ticker\"])\n",
    "    return np.array([name for (name,group) in groups if group[flags].any(axis=1).any()])\n",
    "\n",
    "def findValidStocks(df_prices):\n",
    "    flags  = [HAS_NAN_DAYS,TOO_FEW_DAYS,EXTREM_HL]\n",
    "    groups = df_prices.groupby([\"Ticker\"])\n",
    "    return np.array([name for (name,group) in groups if not group[flags].any(axis=1).any()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fead46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from lib.data.lists import *\n",
    "import torch\n",
    "from torch.tensor import *\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "class Data():\n",
    "    def __init__(self, df_prices):\n",
    "        self.df_prices = df_prices\n",
    "        self.np_prices = None\n",
    "        self.seq_len   = None\n",
    "        self.columns   = None  #training and test columns\n",
    "        #insert a row counter/index\n",
    "        #if \"idx\" not in self.df_prices.columns:\n",
    "        #    self.df_prices.insert(loc=0, column=\"idx\", value=np.arange(len(self.df_prices),dtype=int))\n",
    "        self.df_prices[\"idx\"] = np.arange(len(self.df_prices),dtype=int)\n",
    "        \n",
    "    #set sequence length and columns used for training and test\n",
    "    def changeTraining(self,seq_len,columns,n_predict_columns, train_test_default):\n",
    "        self.seq_len = seq_len\n",
    "        self.columns = columns\n",
    "        self.n_predict_columns = n_predict_columns\n",
    "        \n",
    "        #point to the first predictabel sample in a stock. \n",
    "        #this sample is predicted using df_prices[:seq_len,columns]\n",
    "        ix_predict = np.arange(len(self.df_prices),dtype=int)        \n",
    "        for g,d in self.df_prices.groupby([\"Ticker\"]):\n",
    "            ix_predict[d.idx[:seq_len]] = -1\n",
    "        self.df_prices[\"ix_predict\"] = ix_predict\n",
    "        self.np_prices = self.df_prices[self.columns].to_numpy()\n",
    "\n",
    "        self.df_prices[TRAIN_TEST] = train_test_default\n",
    "        \n",
    "    def getTensor(self, ix, r_mixin=0.0, r_ix=None):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "\n",
    "        prices = self.np_prices #readability and local pointer is faster if used multiple times\n",
    "        pi     = prices[ix - self.seq_len : ix ] \n",
    "        pt     = prices[ix, :self.n_predict_columns ]   \n",
    "        if r_ix:\n",
    "            #mix with another sequence\n",
    "            ro  = 1 - r_mixin\n",
    "            pi  = pi*ro + r_mixin*prices[r_ix - self.seq_len : r_ix]\n",
    "            pt  = pt*ro + r_mixin*prices[r_ix,:self.n_predict_columns]\n",
    "        return torch.tensor( pi ), torch.tensor( pt ) #, index\n",
    "    \"\"\"\n",
    "    def getSequenceIndexByStock(self, stocks):\n",
    "        print(f\"getSequenceIndexByStock\")\n",
    "        idx_seq = self.df_prices.ix_predict.loc[stocks].to_numpy()\n",
    "        idx_seq = idx_seq[idx_seq>=0]\n",
    "        return idx_seq\n",
    "    \n",
    "    def getSequenceIndexByTrainTest(self, train_test):\n",
    "        print(f\"getSequenceIndexByTrainTest train_test:{train_test}\")\n",
    "        ix      = self.df_prices[TRAIN_TEST].eq(train_test).to_numpy()\n",
    "        idx_seq = self.df_prices.ix_predict.loc[ix].to_numpy()\n",
    "        idx_seq = idx_seq[idx_seq>=0]\n",
    "        return idx_seq\n",
    "    \"\"\"\n",
    "    def getSequenceIndex(self, stocks, train_test):\n",
    "        ix      = self.df_prices[TRAIN_TEST].eq(train_test)\n",
    "        idx_seq = self.df_prices.loc[ix].loc[stocks].ix_predict.to_numpy()\n",
    "        idx_seq = idx_seq[idx_seq>=0]\n",
    "        return idx_seq\n",
    "    \n",
    "    \"\"\"\n",
    "    def getTensor(self, ix, r_mixin=0.0, ix_r=None):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "\n",
    "        prices = self.np_prices #readability and local pointer is faster if used multiple times\n",
    "        ixb    = ix - self.seq_len\n",
    "        ixe    = ix+len(self.columns)\n",
    "        pi     = torch.tensor( prices[ixb:ix ] )\n",
    "        pt     = torch.tensor( prices[ ix,:]   )\n",
    "        if r_mixin > 0.0:\n",
    "            #mix with another sequence\n",
    "            ix  = ix_r\n",
    "            ixb = ix - self.seq_len\n",
    "            ixe = ix + len(self.columns)\n",
    "            ro  = 1 - r_mixin\n",
    "            #print(f\"ixb,ix,ixe: {ixb,ix,ixe}\")\n",
    "            pi  = pi.mul_(ro) + torch.tensor( prices[ixb:ix] ).mul_(r_mixin)\n",
    "            pt  = pt.mul_(ro) + torch.tensor( prices[ix,:]   ).mul_(r_mixin)\n",
    "            #pi  = pi*ro + torch.tensor( prices[ixb:ix] )*r_mixin\n",
    "            #pt  = pt*ro + torch.tensor( prices[ix,:]   )*r_mixin\n",
    "            #pi  = pi.mul_(ro).add_( torch.tensor( prices[ixb:ix] ).mul_(r_mixin) )\n",
    "            #pt  = pt.mul_(ro).add_( torch.tensor( prices[ix,:]   ).mul_(r_mixin) )\n",
    "        return pi, pt #, index\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb704382",
   "metadata": {},
   "source": [
    "df_prices = loadShareprices()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dad18109",
   "metadata": {},
   "source": [
    "data     = Data(df_prices)\n",
    "seq_len  = 3\n",
    "columns  = [CLOSE,OPEN]\n",
    "data.changeTraining(seq_len,columns,n_predict_columns=2)\n",
    "print(data.df_prices[:6])\n",
    "%time d = data.getTensor(ix=3)#, r_mixin=0.5, r_ix=4)\n",
    "%timeit -r 10 d = data.getTensor(ix=3)#, r_mixin=0.5, r_ix=4)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import random\n",
    "#Create a dataset that uses all the stocks and daily prices\n",
    "#In order to save memory the df_prices is the same for both training and validation.\n",
    "#np_prices contains interleaved prices of the columns used for training/validation\n",
    "#fx if the require columns are \"open\", \"close\". Then np_prices contain row, columns values from\n",
    "#df_price in the following order : open_row1, close_row1, open_row2, close_row2, ...\n",
    "\n",
    "#for now self.np_prices are dublicated. Thus using more memory than needed.\n",
    "#Test and validation contain different stock taken drom the same df_prices\n",
    "\n",
    "#stocks    : are the stock tickers\n",
    "#stock_days: is the number of days pr stock. The number of days is in different for each stock\n",
    "#            The total number of samples is stock_days.sum()\n",
    "#batch_size: is the number of stocks in a batch\n",
    "#seq_length: is the number of stocks days in a batch.\n",
    "#the number of sample in the batch is seq_length*len(column_names)\n",
    "\n",
    "#As for now the dataset progress sequentially through the data during an epoch from a random offset.\n",
    "#Notice that there is no end of sequence-token to reset the model when the sequencen wraps around\n",
    "TRAIN_TEST   = \"train_test\"\n",
    "\n",
    "        \n",
    "class OHLCDataset(torch.utils.data.Dataset):\n",
    "    #x, y significes input vs output\n",
    "    def __init__(self, data, stocks, train_test):\n",
    "        self.data         = data #share data\n",
    "        self.stocks       = stocks\n",
    "\n",
    "        self.mixin        = 0.0  #ration to mix to sequences\n",
    "        self.do_mix       = False\n",
    "        self.train_test   = train_test        \n",
    "        \n",
    "        #Index to all start of sequences in the dataset\n",
    "        #The target is taken from the day after the sequence\n",
    "        self.idx_seq      = None\n",
    "        #self.idx_seq      = data.getSequenceIndex(stocks)\n",
    "        \n",
    "        \n",
    "    def changeAugmentation( self, mixing=0.5 ):\n",
    "        self.mixin  = mixing\n",
    "        self.do_mix = self.mixin>0.0\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.idx_seq is None: \n",
    "            self.idx_seq = self.data.getSequenceIndex(self.stocks, self.train_test)\n",
    "            #self.idx_seq = data.getSequenceIndexByTrainTest(self.train_test)\n",
    "            \n",
    "        return len(self.idx_seq)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        ix = self.idx_seq[index]\n",
    "\n",
    "        #if self.do_mix then make augmentation by mixin with another sequence        \n",
    "        r_ix    = self.idx_seq[random.randint(0, len(self)-1)] if self.do_mix else None\n",
    "        r_mixin = random.uniform(0, self.mixin )               if self.do_mix else 0.0\n",
    "            \n",
    "        return self.data.getTensor(ix=ix, r_mixin=r_mixin, r_ix=r_ix)\n",
    "\n",
    "    #stocks: stocks that you want the price_input and target for\n",
    "    def getBatch(self, stocks):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        #extract the rows in df_proces containing the stocks in the batch\n",
    "        idx = self.getSequenceIndexing(stocks);\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        df_prices_selected = self.df_prices[ self.df_prices.index.get_level_values(0).isin(stocks) ]\n",
    "        stock_grps         = df_prices_selected.groupby([\"Ticker\"])\n",
    "        idx, seq_len = [], self.seq_length\n",
    "        for name,group in stock_grps:\n",
    "            idx.extend(group[\"idx\"].values[seq_len:len(group)])\n",
    "        idx = np.array(idx,dtype=int)\n",
    "\n",
    "        pt = self.df_prices.iloc[idx]\n",
    "        pi = [self.df_prices.iloc[ib:ie, self.ix_columns].values for ib,ie in zip(pt.idx - seq_len, pt.idx)]\n",
    "        return np.array(pi), self.df_prices.iloc[idx].copy()\n",
    "        \"\"\"\n",
    "\n",
    "    def dataloader(self, batch_size:int, shuffle:bool, num_workers:int=0, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(self, batch_size=batch_size, shuffle=shuffle,\n",
    "                                           num_workers=num_workers, drop_last=drop_last)\n",
    "\n",
    "    #method can be by \"stock\" or by \"time\"\n",
    "    def split2train_test(self, method, test_percentage):\n",
    "        \n",
    "        ix_TRAIN_TEST = self.data.df_prices.columns.get_loc(TRAIN_TEST)\n",
    "        if method == \"stock\":\n",
    "            #split the stocks in train and test stocks\n",
    "            #It might be better to make a split in historical vs new prices\n",
    "            ix_all   = np.arange(len(self.stocks),dtype=int)\n",
    "            np.random.shuffle(ix_all)\n",
    "\n",
    "            nb_test  = int(round(test_percentage*len(self.stocks)))\n",
    "            ix_train = ix_all[nb_test:]\n",
    "            ix_test  = ix_all[:nb_test]\n",
    "            train_stocks = self.stocks[ix_train]\n",
    "            test_stocks  = self.stocks[ix_test]\n",
    "            #self.data.df_prices.loc[train_stocks,TRAIN_TEST] = \"train\"\n",
    "            #self.data.df_prices.loc[test_stocks,TRAIN_TEST ] = \"test\"\n",
    "            \n",
    "            ix_train = []\n",
    "            ix_test  = []\n",
    "            #the first seq_len sample are used for training but the first value to predict is located at seq_len\n",
    "            for s,d in self.data.df_prices.groupby([\"Ticker\"]):\n",
    "                if s in self.stocks:\n",
    "                    if s in test_stocks:\n",
    "                        ix_test.extend(d.idx.iloc[self.data.seq_len:])\n",
    "                    else:\n",
    "                        ix_train.extend(d.idx.iloc[self.data.seq_len:])\n",
    "                        \n",
    "            #print(f\"len(ix_train),len(ix_test):{len(ix_train),len(ix_test)}\")\n",
    "            self.data.df_prices.iloc[ix_train,ix_TRAIN_TEST] = \"train\"\n",
    "            self.data.df_prices.iloc[ix_test, ix_TRAIN_TEST] = \"test\"\n",
    "            \n",
    "            train_ds = self.__class__(self.data, train_stocks, \"train\")\n",
    "            test_ds  = self.__class__(self.data, test_stocks,  \"test\")\n",
    "        elif method == \"time\":\n",
    "            #split by time\n",
    "            ix_train = []\n",
    "            ix_test  = []\n",
    "            for s,d in self.data.df_prices.groupby([\"Ticker\"]):\n",
    "                if s in self.stocks:\n",
    "                    #calc number of testdata in the future pr stock\n",
    "                    nb_test  = int(round(test_percentage*(len(d)-self.data.seq_len)))\n",
    "                    ix_train.extend(d.idx.iloc[:-nb_test])\n",
    "                    ix_test.extend( d.idx.iloc[-nb_test:])\n",
    "            #print(f\"len(ix_train),len(ix_test):{len(ix_train),len(ix_test)}\")\n",
    "            self.data.df_prices.iloc[ix_train,ix_TRAIN_TEST] = \"train\"\n",
    "            self.data.df_prices.iloc[ix_test, ix_TRAIN_TEST] = \"test\"\n",
    "                    \n",
    "            train_ds = self.__class__(self.data, self.stocks, \"train\")\n",
    "            test_ds  = self.__class__(self.data, self.stocks,  \"test\")\n",
    "        \n",
    "        return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49255ef9",
   "metadata": {},
   "source": [
    "#from numpy.random import default_rng\n",
    "len_idx =10\n",
    "rng = np.random.default_rng()\n",
    "ri=rand_idx_sequence = rng.integers(0, len_idx,size=len_idx)\n",
    "rf=rand_frations = rng.random(len_idx)\n",
    "print(ri)\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def loadShareprices():\n",
    "    #Load shareprices for testing and development\n",
    "    dataPath = initiateSimFin(key='free')\n",
    "    print(f\"dataPath:{dataPath} exists:{dataPath.exists()}\")\n",
    "\n",
    "    # Data for USA.\n",
    "    market = 'us'\n",
    "    # Daily Share-Prices.\n",
    "    return sf.load_shareprices(variant='daily', market=market)\n",
    "\n",
    "\n",
    "PREV_CLOSE = \"previous_close\"\n",
    "def alignPreviousClose(df_prices):\n",
    "    # Make a new column to show the closing price from the previous day on the same line as current day.\n",
    "    # This is done using the shift function for the dataserie\n",
    "    #\n",
    "    # Result: All stock and prices are listed in the same tabel. Therefore, the firat priceline of each stock vil now\n",
    "    # contain the close of the previous stock. For the first stock this value vil be \"nan\".\n",
    "    # These incoherent pricelines are removed in the nest step\n",
    "\n",
    "    #if PREV_CLOSE not in df_prices.columns:\n",
    "    if not PREV_CLOSE in df_prices.columns:\n",
    "        df_prices.insert(df_prices.columns.get_loc(OPEN), PREV_CLOSE, df_prices[CLOSE].shift(), allow_duplicates=False)\n",
    "\n",
    "    #identify the first stock in each stockgroup and the remove it\n",
    "    stock_name    = df_prices.index.get_level_values(0)\n",
    "    new_stock     = np.ones(len(df_prices), dtype=bool)\n",
    "    new_stock[1:] = stock_name[0:len(stock_name)-1] != stock_name[1:len(stock_name)]\n",
    "    df_prices.drop(df_prices.index[new_stock], axis=0, inplace=True)\n",
    "    return df_prices\n",
    "\n",
    "#extrem_increase,extrem__decrease = 2.5, -.73\n",
    "#extrem_increase,extrem__decrease = 1.5, -.5\n",
    "def procesSharePrices(df_prices, minimum_tradingdays=180, extrem_increase = 0.5, extrem__decrease = -0.5):\n",
    "\n",
    "    # load and identify valid data\n",
    "    df_prices = alignPreviousClose(df_prices)\n",
    "    df_prices = logMinusPreviousClose(df_prices)\n",
    "\n",
    "    flagstocks_extrem_hl(df_prices, extrem_increase, extrem__decrease)\n",
    "    flagstocks_too_few_trading_days(df_prices,minimum_tradingdays)\n",
    "    flagstocks_with_nan_days(df_prices)\n",
    "\n",
    "    validStocks, inValidStocks = findValidStocks(df_prices), findInValidStocks(df_prices)\n",
    "\n",
    "    stock_grps = df_prices.groupby([\"Ticker\"])\n",
    "    stocks     = np.array(list(stock_grps.groups))\n",
    "    sizes      = stock_grps.size()\n",
    "    print(f\"number of stocks:         {len(stocks)}\")\n",
    "    print(f\"number of valid stocks:   {len(validStocks)}\")\n",
    "    print(f\"number of invalid stocks: {len(inValidStocks)}\")\n",
    "\n",
    "    print(f\"smallest pricelines pr stock: {sizes.sort_values()[:5]}\")\n",
    "    print(f\"longest pricelines pr stock:  {sizes.sort_values()[-5:]}\")\n",
    "\n",
    "    return df_prices, stocks, validStocks, inValidStocks\n",
    "\n",
    "predict_prefix=\"predict_\"\n",
    "PREDICT_OPEN  = predict_prefix+OPEN\n",
    "PREDICT_HIGH  = predict_prefix+HIGH\n",
    "PREDICT_LOW   = predict_prefix+LOW\n",
    "PREDICT_CLOSE = predict_prefix+CLOSE\n",
    "\n",
    "def predict_stocks(dataset, modelmanager, stocks, tfm_input ):\n",
    "    price_sequences, price_targets = dataset.getBatch(stocks=stocks)\n",
    "    predictions    = modelmanager.predict(price_sequences, tfm_input)\n",
    "\n",
    "    # inser the preduction in price_targets\n",
    "    prediction_columns = [ predict_prefix + name for name in dataset.column_names ]\n",
    "    print(prediction_columns)\n",
    "    for idx,name in enumerate(prediction_columns):\n",
    "        print(idx, name)\n",
    "        if name in price_targets.columns :\n",
    "            price_targets.drop([name], axis='columns', inplace=True)\n",
    "        else:\n",
    "            price_targets.insert(len(price_targets.columns), name, predictions[:,idx-1].numpy())\n",
    "    return price_targets, prediction_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e87b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "#Convert OHLC to percentages of the previous days closing price\n",
    "#tahe the log onallprice action and subtract Previousclose from from price\n",
    "#to arrive at log percentage change relativ til previous close\n",
    "def logMinusPreviousClose(df_prices):\n",
    "    df_prices[[PREV_CLOSE,OPEN,CLOSE,LOW,HIGH]] = df_prices[[PREV_CLOSE,OPEN,CLOSE,LOW,HIGH]].apply(np.log)\n",
    "    df_prices[[OPEN,CLOSE,LOW,HIGH]]            = df_prices[[OPEN,CLOSE,LOW,HIGH]].sub(df_prices[PREV_CLOSE],axis=0)\n",
    "    return df_prices\n",
    "\n",
    "normalized_suffix=\"_normalized\"\n",
    "OPEN_NORM  = OPEN +normalized_suffix\n",
    "HIGH_NORM  = HIGH +normalized_suffix\n",
    "LOW_NORM   = LOW  +normalized_suffix\n",
    "CLOSE_NORM = CLOSE+normalized_suffix\n",
    "\n",
    "def normalizeData( df_prices, stats, normalized_suffix=normalized_suffix):\n",
    "    normalized_columns = []\n",
    "    for c in [OPEN,HIGH,LOW,CLOSE]:\n",
    "        mean,std = [stats.loc[\"mean\",c], stats.loc[\"std\",c]]\n",
    "        normalized_columns.append( c+normalized_suffix )\n",
    "        df_prices[c+normalized_suffix] = df_prices[c].div(std)\n",
    "    return df_prices,normalized_columns\n",
    "\n",
    "def truncateExtremes(df_prices,training_columns,stats, percent_min, percent_max):\n",
    "    for c in training_columns:\n",
    "        v_min,v_max = [stats.loc[percent_min,c], stats.loc[percent_max,c]]\n",
    "        ix = df_prices[c] < v_min\n",
    "        df_prices.loc[ix,c] = v_min\n",
    "        ix = df_prices[c] > v_max\n",
    "        df_prices.loc[ix,c] = v_max\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f814f0",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727c4a2",
   "metadata": {},
   "source": [
    "# Statics on the mature stocks\n",
    "min, max, mean, std, percentiles\n",
    "calculate the normalization numbers\n",
    "\n",
    "# Create dataset\n",
    "The dataset must a batch with number of stock = batch_size\n",
    "Each sequence of stockprice (ohlc) return from the dataset must be of the samme sequence_length During the training the network will process the sequence day by day\n",
    "\n",
    "At the beginning of each epoch It must be possible to shuffle the stock It must be possible to shuffle the start date of the stockprices for each stock\n",
    "\n",
    "The dataframe will remain fixed during the training using indirect indexing This will be faster and use less memory for large dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd4195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataPath:/Users/kasparlund/simfin_data exists:True\n",
      "Dataset \"us-shareprices-daily\" on disk (0 days old).\n",
      "- Loading from disk ... Done!\n",
      "CPU times: user 26.8 s, sys: 1.54 s, total: 28.3 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%time df_prices = loadShareprices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d5351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stocks:         2618\n",
      "number of valid stocks:   1626\n",
      "number of invalid stocks: 992\n",
      "smallest pricelines pr stock: Ticker\n",
      "NLN      1\n",
      "LMND     2\n",
      "DNB      3\n",
      "ACI      6\n",
      "OPEN    12\n",
      "dtype: int64\n",
      "longest pricelines pr stock:  Ticker\n",
      "HTLD     3400\n",
      "HTH      3400\n",
      "IBM      3400\n",
      "KEY      3400\n",
      "FCAUS    3425\n",
      "dtype: int64\n",
      "CPU times: user 52.2 s, sys: 3.42 s, total: 55.7 s\n",
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%time df_prices, stocks, validStocks, inValidStocks = procesSharePrices(df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe7d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.381883e+06</td>\n",
       "      <td>4.381883e+06</td>\n",
       "      <td>4.381883e+06</td>\n",
       "      <td>4.381883e+06</td>\n",
       "      <td>4.381883e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.467543e+00</td>\n",
       "      <td>1.129824e-04</td>\n",
       "      <td>1.484703e-02</td>\n",
       "      <td>-1.531470e-02</td>\n",
       "      <td>1.773332e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.839195e-01</td>\n",
       "      <td>1.401605e-02</td>\n",
       "      <td>2.168032e-02</td>\n",
       "      <td>2.302438e-02</td>\n",
       "      <td>2.629342e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.912023e+00</td>\n",
       "      <td>-4.829644e-01</td>\n",
       "      <td>-4.327939e-01</td>\n",
       "      <td>-4.995624e-01</td>\n",
       "      <td>-4.867261e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02%</th>\n",
       "      <td>-3.912023e+00</td>\n",
       "      <td>-1.978694e-01</td>\n",
       "      <td>-1.430594e-01</td>\n",
       "      <td>-3.279561e-01</td>\n",
       "      <td>-2.680589e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>1.071584e+00</td>\n",
       "      <td>-4.015526e-02</td>\n",
       "      <td>-1.898795e-02</td>\n",
       "      <td>-1.016918e-01</td>\n",
       "      <td>-7.626433e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.888704e+00</td>\n",
       "      <td>-3.805386e-03</td>\n",
       "      <td>3.733247e-03</td>\n",
       "      <td>-2.104773e-02</td>\n",
       "      <td>-9.978700e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.489513e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.027246e-02</td>\n",
       "      <td>-1.016560e-02</td>\n",
       "      <td>2.618829e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.049173e+00</td>\n",
       "      <td>4.390786e-03</td>\n",
       "      <td>2.038105e-02</td>\n",
       "      <td>-3.316753e-03</td>\n",
       "      <td>1.072309e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>5.858824e+00</td>\n",
       "      <td>3.846628e-02</td>\n",
       "      <td>9.619240e-02</td>\n",
       "      <td>1.830969e-02</td>\n",
       "      <td>7.492761e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.98%</th>\n",
       "      <td>1.240856e+01</td>\n",
       "      <td>1.649563e-01</td>\n",
       "      <td>2.813818e-01</td>\n",
       "      <td>1.180017e-01</td>\n",
       "      <td>2.340006e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.275121e+01</td>\n",
       "      <td>4.894546e-01</td>\n",
       "      <td>4.985555e-01</td>\n",
       "      <td>4.795731e-01</td>\n",
       "      <td>4.818492e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_close          Open          High           Low         Close\n",
       "count     4.381883e+06  4.381883e+06  4.381883e+06  4.381883e+06  4.381883e+06\n",
       "mean      3.467543e+00  1.129824e-04  1.484703e-02 -1.531470e-02  1.773332e-04\n",
       "std       9.839195e-01  1.401605e-02  2.168032e-02  2.302438e-02  2.629342e-02\n",
       "min      -3.912023e+00 -4.829644e-01 -4.327939e-01 -4.995624e-01 -4.867261e-01\n",
       "0.02%    -3.912023e+00 -1.978694e-01 -1.430594e-01 -3.279561e-01 -2.680589e-01\n",
       "1%        1.071584e+00 -4.015526e-02 -1.898795e-02 -1.016918e-01 -7.626433e-02\n",
       "25%       2.888704e+00 -3.805386e-03  3.733247e-03 -2.104773e-02 -9.978700e-03\n",
       "50%       3.489513e+00  0.000000e+00  1.027246e-02 -1.016560e-02  2.618829e-04\n",
       "75%       4.049173e+00  4.390786e-03  2.038105e-02 -3.316753e-03  1.072309e-02\n",
       "99%       5.858824e+00  3.846628e-02  9.619240e-02  1.830969e-02  7.492761e-02\n",
       "99.98%    1.240856e+01  1.649563e-01  2.813818e-01  1.180017e-01  2.340006e-01\n",
       "max       1.275121e+01  4.894546e-01  4.985555e-01  4.795731e-01  4.818492e-01"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistics on the mature stocks\n",
    "stats = df_prices.loc[validStocks,[PREV_CLOSE,OPEN,HIGH,LOW,CLOSE]].describe(percentiles=\\\n",
    "                                                                             [0.0002, 0.01, 0.25, 0.75, 0.99, 0.9998])        \n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e7b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage =>0: 52.54537832251569\n",
      "percentage ==0: 2.2496264733677283\n",
      "percentage  <0: 47.45462167748432\n",
      "mean=0 percentage =>0: 50.174274392994974\n",
      "mean=0 percentage ==0: 0.0\n",
      "mean=0 percentage  <0: 49.825725607005026\n",
      "CPU times: user 338 ms, sys: 114 ms, total: 452 ms\n",
      "Wall time: 449 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_valid =df_prices.loc[validStocks]\n",
    "print( f\"percentage =>0: {df_valid[CLOSE].ge(0).sum()/len(df_valid)*100}\")\n",
    "print( f\"percentage ==0: {df_valid[CLOSE].eq(0).sum()/len(df_valid)*100}\")\n",
    "print( f\"percentage  <0: {df_valid[CLOSE].lt(0).sum()/len(df_valid)*100}\")\n",
    "\n",
    "print( f\"mean=0 percentage =>0: {(df_valid[CLOSE]-stats.loc['mean',CLOSE]).ge(0).sum()/len(df_valid)*100}\")\n",
    "print( f\"mean=0 percentage ==0: {(df_valid[CLOSE]-stats.loc['mean',CLOSE]).eq(0).sum()/len(df_valid)*100}\")\n",
    "print( f\"mean=0 percentage  <0: {(df_valid[CLOSE]-stats.loc['mean',CLOSE]).lt(0).sum()/len(df_valid)*100}\")\n",
    "del df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcae053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.8 s, sys: 1.08 s, total: 4.88 s\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from lib.learner.learner import*\n",
    "from lib.learner.optimizers import*\n",
    "from lib.model.model import*\n",
    "from lib.model.modelmanager import*\n",
    "import torch.nn as nn\n",
    "\n",
    "training_columns = [CLOSE,OPEN]\n",
    "#mean is so close to zero so we only devide by std\n",
    "stats = df_prices.loc[validStocks].describe(percentiles=[0.0002, 0.01, 0.25, 0.75, 0.99, 0.9998])\n",
    "df_prices, normalized_columns = normalizeData(df_prices,stats)\n",
    "\n",
    "#truncate extrems\n",
    "stats = df_prices.loc[validStocks,normalized_columns].describe(percentiles=[0.0002, 0.01, 0.25, 0.75, 0.99, 0.9998])\n",
    "df_prices = truncateExtremes(df_prices,normalized_columns, stats, \"1%\", \"99%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabc053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_length: 360 training columns = ['Close_normalized', 'Open_normalized'] n_predict_columns:1\n",
      "len(ohlc_ds):3800999\n"
     ]
    }
   ],
   "source": [
    "seq_length = 360\n",
    "training_columns = [CLOSE_NORM,OPEN_NORM]\n",
    "n_predict_columns=1\n",
    "print(f\"seq_length: {seq_length} training columns = {training_columns} n_predict_columns:{n_predict_columns}\")\n",
    "\n",
    "train_test_default = \"default\"\n",
    "data = Data(df_prices)\n",
    "data.changeTraining(seq_length,training_columns,n_predict_columns, train_test_default)\n",
    "\n",
    "ohlc_ds = OHLCDataset(data, validStocks, train_test_default)\n",
    "print(f\"len(ohlc_ds):{len(ohlc_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ValidStocks, train, test inValid: (1626, 1220, 406, 992)\n",
      "number of samples: len(ohlc_ds),len(train_ds),len(test_ds): (3800999, 2862653, 938346)\n",
      "CPU times: user 3.56 s, sys: 657 ms, total: 4.22 s\n",
      "Wall time: 4.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_ds, test_ds = ohlc_ds.split2train_test(\"stock\",0.25)\n",
    "#train_ds, test_ds = ohlc_ds.split2train_test(\"time\",0.25)\n",
    "train_ds.changeAugmentation( mixing=0.5 )\n",
    "\n",
    "print(f\"number of ValidStocks, train, test inValid: {len(ohlc_ds.stocks), len(train_ds.stocks), len(test_ds.stocks), len(inValidStocks)}\")\n",
    "print(f\"number of samples: len(ohlc_ds),len(train_ds),len(test_ds): {len(ohlc_ds),len(train_ds),len(test_ds)}\")\n",
    "databunch = DataBunch(train_ds.dataloader(batch_size=2048, shuffle=True,  drop_last=True), \\\n",
    "                      test_ds.dataloader( batch_size=4096, shuffle=False, drop_last=False), \\\n",
    "                      c_in=len(ohlc_ds.data.columns), c_out=len(ohlc_ds.data.columns))\n",
    "\n",
    "#print(\"the following lengths must be the same\")\n",
    "#%time stock_days = [len(ohlc_ds.stock_grps.get_group(stock)) for stock in ohlc_ds.stocks]\n",
    "#print(len(ohlc_ds), sum(stock_days)-len(stock_days)*(seq_length+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ad486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800999, 0.7531317424708609, 0.24686825752913905)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ohlc_ds),len(train_ds)/len(ohlc_ds),len(test_ds)/len(ohlc_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ab1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3091016, 2838643, 962356)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df_prices[TRAIN_TEST].eq(\"default\").sum(), \\\n",
    "data.df_prices[TRAIN_TEST].eq(\"train\").sum(), \\\n",
    "data.df_prices[TRAIN_TEST].eq(\"test\").sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "140759b3",
   "metadata": {},
   "source": [
    "split by stock: default, train, test: 3800999 2828082 972917\n",
    "split by time:  default, train, test: 3800999 2850744 950255\n",
    "both have the same number of samples. ie 2828082+972917== 2850744+950255"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d52bcb5f",
   "metadata": {},
   "source": [
    "%time l = [len(b[0]) for b in databunch.train_dl]\n",
    "#CPU times: user 1min 52s, sys: 2.09 s, total: 1min 54s\n",
    "#Wall time: 1min 54s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad88c125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>ix_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-10</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   idx  ix_predict\n",
       "Ticker Date                       \n",
       "A      2007-01-04    0          -1\n",
       "       2007-01-05    1          -1\n",
       "       2007-01-08    2          -1\n",
       "       2007-01-09    3          -1\n",
       "       2007-01-10    4          -1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices[[\"idx\",\"ix_predict\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 02_lists.ipynb.\n",
      "Converted 03_images.ipynb.\n",
      "Converted 05_Learner.ipynb.\n",
      "Converted 05_model.ipynb.\n",
      "Converted 06_modelmanger.ipynb.\n",
      "Converted 07_optimizers.ipynb.\n",
      "Converted app_image_01_mnist_optimizers.ipynb.\n",
      "Converted app_image_02_imagenette_optimizers.ipynb.\n",
      "Converted fin_01_candlestick.ipynb.\n",
      "Converted fin_02_simfin_data-Copy1.ipynb.\n",
      "Converted fin_02_simfin_data.ipynb.\n",
      "Converted fin_02_simfin_generated_data.ipynb.\n",
      "Converted fin_02_simfin_training.ipynb.\n",
      "Converted fin_03_graphs.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted parallel.ipynb.\n",
      "Converted parallel_extern.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b2b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
