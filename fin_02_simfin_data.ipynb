{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52aff0a",
   "metadata": {},
   "source": [
    "# TODO fase 1\n",
    " - calculate predictions for a stock fx apple\n",
    " - statistics for the predictions: distribution of errors, percentage prediction with the right direction:  close>open, open<close\n",
    " - visualize ohlc as bands and on stock curve\n",
    " - split in train, test so that test data are taken from time periodens after the training data and possibly from stocks that have not been used for training \n",
    "\n",
    " - tjek quantile objective function\n",
    " - objectiv function that weigh open and closing prices higher\n",
    "\n",
    " - add day of week to training data\n",
    " - speed up training: improve the pandas part by 60 times\n",
    "                                                                                                                                   \n",
    "# TODO fase 2\n",
    " - language modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp finance.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3cd767",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55bdddce",
   "metadata": {},
   "source": [
    "#add the parent directiry so thatwecan access modules the and inits subdirectories\n",
    "import sys, os, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir  = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from lib.data.lists import *\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the main functionality from the SimFin Python API.\n",
    "import simfin as sf\n",
    "\n",
    "# Import names used for easy access to SimFin's data-columns.\n",
    "from simfin.names import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d1707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version of the SimFin Python API.\n",
    "sf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181fd919",
   "metadata": {},
   "source": [
    "# Define location of Simfin data and license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f825c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def initiateSimFin(key='free'):\n",
    "    # SimFin data-directory.\n",
    "    sf.set_data_dir('~/simfin_data/')\n",
    "    # SimFin load API key or use free data.\n",
    "    sf.load_api_key(path='~/simfin_api_key.txt', default_key=key)\n",
    "    return Path.home()/\"simfin_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050d423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataPath:/Users/kasparlund/simfin_data exists:True\n",
      "Dataset \"us-shareprices-daily\" on disk (6 days old).\n",
      "- Loading from disk ... Done!\n",
      "CPU times: user 26.1 s, sys: 1.4 s, total: 27.5 s\n",
      "Wall time: 27.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SimFinId</th>\n",
       "      <th>Open</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Dividend</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Shares Outstanding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>45846</td>\n",
       "      <td>34.99</td>\n",
       "      <td>34.05</td>\n",
       "      <td>35.48</td>\n",
       "      <td>34.30</td>\n",
       "      <td>22.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2574600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>45846</td>\n",
       "      <td>34.30</td>\n",
       "      <td>33.46</td>\n",
       "      <td>34.60</td>\n",
       "      <td>34.41</td>\n",
       "      <td>22.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2073700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>45846</td>\n",
       "      <td>34.30</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.40</td>\n",
       "      <td>34.09</td>\n",
       "      <td>22.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2676600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>45846</td>\n",
       "      <td>33.98</td>\n",
       "      <td>33.68</td>\n",
       "      <td>34.08</td>\n",
       "      <td>33.97</td>\n",
       "      <td>22.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1557200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>45846</td>\n",
       "      <td>34.08</td>\n",
       "      <td>33.63</td>\n",
       "      <td>34.32</td>\n",
       "      <td>34.01</td>\n",
       "      <td>22.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1386200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SimFinId   Open    Low   High  Close  Adj. Close  Dividend  \\\n",
       "Ticker Date                                                                     \n",
       "A      2007-01-03     45846  34.99  34.05  35.48  34.30       22.69       NaN   \n",
       "       2007-01-04     45846  34.30  33.46  34.60  34.41       22.76       NaN   \n",
       "       2007-01-05     45846  34.30  34.00  34.40  34.09       22.55       NaN   \n",
       "       2007-01-08     45846  33.98  33.68  34.08  33.97       22.47       NaN   \n",
       "       2007-01-09     45846  34.08  33.63  34.32  34.01       22.50       NaN   \n",
       "\n",
       "                    Volume  Shares Outstanding  \n",
       "Ticker Date                                     \n",
       "A      2007-01-03  2574600                 NaN  \n",
       "       2007-01-04  2073700                 NaN  \n",
       "       2007-01-05  2676600                 NaN  \n",
       "       2007-01-08  1557200                 NaN  \n",
       "       2007-01-09  1386200                 NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Load shareprices for testing and development\n",
    "\n",
    "dataPath = initiateSimFin(key='free')\n",
    "print(f\"dataPath:{dataPath} exists:{dataPath.exists()}\")\n",
    "\n",
    "# Data for USA.\n",
    "market = 'us'\n",
    "# Daily Share-Prices.\n",
    "df_prices = sf.load_shareprices(variant='daily', market=market)\n",
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba164b",
   "metadata": {},
   "source": [
    "# Prepare data for prediction of next days stock prices the next day\n",
    "Create OHLC price changes as percentages relative to the close of the previous day. Furthermore the ohlc is supplemented by the previous days closing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "PREV_CLOSE = \"previous_close\"\n",
    "def alignPrices(df_prices):\n",
    "    # Make a new column to show the closing price from the previous day on the same line as current day. \n",
    "    # This is done using the shift function for the dataserie\n",
    "    # \n",
    "    # Result: All stock and prices are listed in the same tabel. Therefore, the firat priceline of each stock vil now \n",
    "    # contain the close of the previous stock. For the first stock this value vil be \"nan\". \n",
    "    # These incoherent pricelines are removed in the nest step\n",
    "    \n",
    "    #if PREV_CLOSE not in df_prices.columns: \n",
    "    if not PREV_CLOSE in df_prices.columns: \n",
    "        df_prices.insert(df_prices.columns.get_loc(OPEN), PREV_CLOSE, df_prices[CLOSE].shift(), allow_duplicates=False)\n",
    "\n",
    "    #identify the first stock in each stockgroup and the remove it\n",
    "    stock_name    = df_prices.index.get_level_values(0)\n",
    "    new_stock     = np.ones(len(df_prices), dtype=bool)\n",
    "    new_stock[1:] = stock_name[0:len(stock_name)-1] != stock_name[1:len(stock_name)]\n",
    "    df_prices.drop(df_prices.index[new_stock], axis=0, inplace=True)\n",
    "    return df_prices\n",
    "\n",
    "#Convert OHLC to percentages of the previous days closing price\n",
    "def convertToPercentages(df_prices):\n",
    "    df_prices[[OPEN,CLOSE,LOW,HIGH]] = df_prices[[OPEN,CLOSE,LOW,HIGH]].sub(df_prices[PREV_CLOSE],axis=0)\\\n",
    "                                        .div(df_prices[PREV_CLOSE],axis=0)\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "#   extrem_increase,extrem__decrease = [], 2.5, -.73\n",
    "#   extrem_increase,extrem__decrease = [], 1.5, -.5\n",
    "EXTREM_HL = \"extrem_hl\"\n",
    "def flagstocks_extrem_hl(df_prices, extrem_increase, extrem__decrease):\n",
    "    #remove mature stocks with \"nan\" prices\n",
    "    if EXTREM_HL in df_prices.columns: \n",
    "        df_prices.drop(labels=EXTREM_HL,axis=1,inplace=True)\n",
    "                       \n",
    "    gt_p = df_prices[[HIGH]].gt(extrem_increase)\n",
    "    gt_p.insert(0,\"lt\",df_prices[[LOW]].lt(extrem__decrease))\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1,EXTREM_HL,gt_p.any(axis=1))    \n",
    "    return df_prices\n",
    "\n",
    "TOO_FEW_DAYS = \"too_few_days\"\n",
    "def flagstocks_too_few_trading_days(df_prices, minimum_days):\n",
    "    grp_res = df_prices.groupby([\"Ticker\"]).apply(lambda group: len(group) < minimum_tradingdays) \n",
    "    grp_res.name = TOO_FEW_DAYS\n",
    "    merged = df_prices[[SIMFIN_ID]].join(grp_res, on=TICKER)\n",
    "    if TOO_FEW_DAYS in df_prices.columns: \n",
    "        df_prices.drop(labels=TOO_FEW_DAYS,axis=1,inplace=True)\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1, TOO_FEW_DAYS, merged[TOO_FEW_DAYS].values)\n",
    "    return df_prices\n",
    "\n",
    "HAS_NAN_DAYS = \"has_nan_days\"\n",
    "def flagstocks_with_nan_days(df_prices):\n",
    "    grp_res = df_prices.groupby([\"Ticker\"]).apply(lambda group: group[[OPEN,LOW,HIGH,CLOSE]].isnull().values.any() ) \n",
    "    grp_res.name = HAS_NAN_DAYS\n",
    "    merged = df_prices[[SIMFIN_ID]].join(grp_res, on=TICKER)\n",
    "    if HAS_NAN_DAYS in df_prices.columns: \n",
    "        df_prices.drop(labels=HAS_NAN_DAYS,axis=1,inplace=True)\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1, HAS_NAN_DAYS, merged[HAS_NAN_DAYS].values)\n",
    "    return df_prices\n",
    "\n",
    "def findInValidStocks(df_prices):\n",
    "    flags  = [HAS_NAN_DAYS,TOO_FEW_DAYS,EXTREM_HL]\n",
    "    groups = df_prices.groupby([\"Ticker\"])\n",
    "    return np.array([name for (name,group) in groups if group[flags].any(axis=1).any()])\n",
    "\n",
    "def findValidStocks(df_prices):\n",
    "    flags  = [HAS_NAN_DAYS,TOO_FEW_DAYS,EXTREM_HL]\n",
    "    groups = df_prices.groupby([\"Ticker\"])\n",
    "    return np.array([name for (name,group) in groups if not group[flags].any(axis=1).any()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ee3f6",
   "metadata": {},
   "source": [
    "# find valid and invalid stocks\n",
    "#df_prices[df_prices[[HAS_NAN_DAYS,TOO_FEW_DAYS,EXTREM_HL]].any(axis=1)]\n",
    "len(findValidStocks(df_prices)), len(findInValidStocks(df_prices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451f305",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "The dataset must a batch with number of stock = batch_size  \n",
    "Each sequence of stockprice (ohlc) return from the dataset must be of the samme sequence_length\n",
    "During the training the network will process the sequence day by day\n",
    "\n",
    "At the beginning of each epoch\n",
    "    It must be possible to shuffle the stock \n",
    "    It must be possible to shuffle the start date of the stockprices for each stock \n",
    "\n",
    "The dataframe will remain fixed during the training using indirect indexing \n",
    "This will be faster and use less memory for large dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from lib.data.lists import *\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "#Create a dataset that uses all the stocks and daily prices during one epoch\n",
    "#an epoch starts by choosing a new set of stocks at random.\n",
    "\n",
    "#stocks    : are the stock tickers\n",
    "#stock_days: is the number of days pr stock. The number of days is in different for each stock\n",
    "#            The total number of samples is stock_days.sum()\n",
    "#batch_size: is the number of stocks in a batch\n",
    "#seq_length: is the number of stocks days in a batch\n",
    "\n",
    "#The length of the dataset is: stock_days.sum() / (batch_size*sequence_length) rounded to the nearest integer.\n",
    "\n",
    "#When the offset+seq_length+1 exceeds the number of days in the stock then the sequences is\n",
    "#restarted at 0 or a random offset \n",
    "\n",
    "#As for now the dataset progress sequentially through the data during an epoch from a random offset. \n",
    "#Notice that there is no end of sequence-token to reset the model when the sequencen wraps around\n",
    "\n",
    "class OHLCDataset(torch.utils.data.Dataset):\n",
    "    #x, y significes input vs output\n",
    "    def __init__(self, df_prices, stocks, seq_length): \n",
    "        self.df_prices   = df_prices\n",
    "        self.stock_grps  = self.df_prices.groupby([\"Ticker\"])\n",
    "        self.stocks      = np.array(list(self.stock_grps.groups)) if stocks is None else stocks\n",
    "        self.seq_length  = seq_length\n",
    "        self.column_names= [OPEN,HIGH,LOW,CLOSE]\n",
    "        self.ix_columns  = [self.df_prices.columns.get_loc(k) for k in self.column_names]\n",
    "\n",
    "        #Index to all start of sequences in the dataset\n",
    "        #The target is taken from the day after the sequence\n",
    "        self.idx_seq      = None\n",
    "        self.price_values = None\n",
    "\n",
    "    def __len__(self): \n",
    "        if self.idx_seq is None: self.initializeSquenzing()\n",
    "        return len(self.idx_seq)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        ix = self.idx_seq[index,:]\n",
    "        pi = torch.tensor(self.price_values[ix[0]:ix[1]])\n",
    "        pt = torch.tensor(self.price_values[ix[1]])\n",
    "        return pi, pt #, index\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        ix = self.idx_seq[index,0]\n",
    "        pi = torch.tensor(self.price_values[self.idx_seq[index,0]:self.idx_seq[index,1]])\n",
    "        pt = torch.tensor(self.price_values[self.idx_seq[index,1]])\n",
    "        return pi, pt #, index\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        (ib,ie) = self.idx_seq[index,:]\n",
    "        pi = torch.tensor(self.price_values[ib:ie])\n",
    "        pt = torch.tensor(self.price_values[ie])\n",
    "        return pi, pt #, index\n",
    "    def __getitem__(self, index):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        ib = self.idx_seq[index]\n",
    "        ie = ib+self.seq_length\n",
    "        pi = torch.tensor(self.price_values[ib:ie])\n",
    "        pt = torch.tensor(self.price_values[ie])\n",
    "        return pi, pt #, index\n",
    "    \"\"\"\n",
    "    #stocks: stocks that you want the price_input and target for    \n",
    "    def getBatch(self, stocks):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        #extract the rows in df_proces containing the stocks in the batch\n",
    "        pt = self.df_prices[ self.df_prices.index.get_level_values(0).isin(stocks) ]\n",
    "        pi = [self.df_prices.iloc[ib:ie, self.ix_columns].values for ib,ie in zip(pt.idx, pt.idx+self.seq_length)]\n",
    "        return np.array(pi), pt\n",
    "\n",
    "    def initializeSquenzing(self):\n",
    "        #Notice that the dataset cannot be used for a RNN where the data should been returned from a sliding window\n",
    "\n",
    "        #Calculate the start and end of all sequences so that the dataloader can load and shuffle efficiently.  \n",
    "        #add an index column to df_prices that we can used to calcualte start and end of sequences\n",
    "        if not \"idx\" in self.df_prices.columns:\n",
    "            self.df_prices.insert(loc=0, column=\"idx\", value=np.arange(len(df_prices),dtype=int))\n",
    "        \n",
    "        #get an index to all valid samples\n",
    "        idx_begin = [] #list of valid dataset index into the dataframe        \n",
    "        for stock in self.stocks:\n",
    "            group = self.stock_grps.get_group(stock)\n",
    "            idx_begin.extend( group[\"idx\"].values[:len(group)-seq_length] )\n",
    "            \n",
    "        self.idx_seq = np.empty( (len(idx_begin),2), dtype=int)  \n",
    "        self.idx_seq[:,0] = idx_begin\n",
    "        self.idx_seq[:,1] = self.idx_seq[:,0]+1\n",
    "\n",
    "        #self.idx_seq      = np.empyt((len(idx_begin),2), dtype=int)  \n",
    "        #self.idx_seq[:,0] = idx_begin, dtype=int\n",
    "        self.price_values = self.df_prices[self.column_names].values\n",
    "        \n",
    "    def dataloader(self, batch_size:int, shuffle:bool, num_workers:int=0, drop_last=False):\n",
    "        self.initializeSquenzing()\n",
    "        return torch.utils.data.DataLoader(self, batch_size=batch_size, shuffle=shuffle,\n",
    "                                           num_workers=num_workers, drop_last=drop_last)\n",
    "    \n",
    "    def split2train_test(self, test_percentage):\n",
    "        #split the stocks in train and test stocks\n",
    "        #It might be better to make a split in historical vs new prices \n",
    "        ix_all   = np.arange(len(self.stocks),dtype=int)\n",
    "        np.random.shuffle(ix_all)\n",
    "        \n",
    "        nb_test  = int(round(test_percentage*len(self.stocks)))\n",
    "        ix_train = ix_all[nb_test:]\n",
    "        ix_test  = ix_all[:nb_test]\n",
    "        return OHLCDataset(self.df_prices, self.stocks[ix_train], self.seq_length),\\\n",
    "               OHLCDataset(self.df_prices, self.stocks[ix_test],  self.seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f76e5",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.4 s, sys: 1.18 s, total: 44.6 s\n",
      "Wall time: 44.7 s\n",
      "CPU times: user 311 ms, sys: 205 ms, total: 516 ms\n",
      "Wall time: 518 ms\n",
      "CPU times: user 53.2 ms, sys: 17 ms, total: 70.2 ms\n",
      "Wall time: 69.9 ms\n",
      "CPU times: user 1.59 s, sys: 385 ms, total: 1.97 s\n",
      "Wall time: 1.98 s\n",
      "CPU times: user 3.17 s, sys: 463 ms, total: 3.63 s\n",
      "Wall time: 3.64 s\n",
      "CPU times: user 5.04 s, sys: 347 ms, total: 5.39 s\n",
      "Wall time: 5.4 s\n",
      "number of valid stocks:   2033\n",
      "number of invalid stocks: 582\n",
      "smallest pricelines pr stock: Ticker\n",
      "NLN       1\n",
      "WMG       2\n",
      "SSI      17\n",
      "GAMZ     18\n",
      "PCP      24\n",
      "BRCM     25\n",
      "CYRP     26\n",
      "GEPC     29\n",
      "FTRCQ    30\n",
      "MENI     38\n",
      "dtype: int64\n",
      "longest pricelines pr stock:  Ticker\n",
      "HURC    3379\n",
      "HUN     3379\n",
      "HUM     3379\n",
      "HTZ     3379\n",
      "HTLD    3379\n",
      "HTH     3379\n",
      "HT      3379\n",
      "HSY     3379\n",
      "HST     3379\n",
      "KBR     3379\n",
      "dtype: int64\n",
      "CPU times: user 54 s, sys: 2.63 s, total: 56.6 s\n",
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load and identify valid data\n",
    "%time alignPrices(df_prices)\n",
    "%time convertToPercentages(df_prices)\n",
    "\n",
    "seq_length          = 60  #dage\n",
    "minimum_tradingdays = 180 #10*seq_length+1 #dage \n",
    "#extrem_increase,extrem__decrease = 2.5, -.73\n",
    "extrem_increase,extrem__decrease = 1.5, -.5\n",
    "%time flagstocks_extrem_hl(df_prices, extrem_increase, extrem__decrease)\n",
    "%time flagstocks_too_few_trading_days(df_prices,minimum_tradingdays)\n",
    "%time flagstocks_with_nan_days(df_prices)\n",
    "\n",
    "%time validStocks, inValidStocks = findValidStocks(df_prices), findInValidStocks(df_prices)\n",
    "\n",
    "stock_grps = df_prices.groupby([\"Ticker\"])\n",
    "stocks     = np.array(list(stock_grps.groups))\n",
    "sizes      = stock_grps.size()\n",
    "#print(f\"number of stocks:         {len(stocks)}\")\n",
    "print(f\"number of valid stocks:   {len(validStocks)}\")\n",
    "print(f\"number of invalid stocks: {len(inValidStocks)}\")\n",
    "#print(f\"number of extrem stocks:   {len(extrem_stocks)}\")\n",
    "\n",
    "print(f\"smallest pricelines pr stock: {sizes.sort_values()[:10]}\")\n",
    "print(f\"longest pricelines pr stock:  {sizes.sort_values()[-10:]}\")\n",
    "\n",
    "\n",
    "#len(df_prices), len(df_prices.loc[stocks[bdx_mature_stocks]]), \\\n",
    "#len(df_prices.loc[stocks[bdx_mature_stocks]])/len(df_prices)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb1506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stocks, train stocks, test stocks: 2033, 1525, 508\n",
      "CPU times: user 3.86 s, sys: 610 ms, total: 4.47 s\n",
      "Wall time: 4.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from lib.learner.learner import*\n",
    "from lib.learner.optimizers import*\n",
    "from lib.model.model import*\n",
    "from lib.model.modelmanager import*\n",
    "import torch.nn as nn\n",
    "\n",
    "#each priceline has 4 datapoint:[OPEN,LOW,HIGH,CLOSE]\n",
    "#batchsize is the number of stocks processed in parallel\n",
    "\n",
    "#ohlc: almost all day to day variation are in the the range -1 to 1.\n",
    "#For now we do not normalize the input. However we will have to do it sooner or later\n",
    "\n",
    "#seq_length=45\n",
    "ohlc_ds = OHLCDataset(df_prices, stocks=validStocks, seq_length=seq_length)\n",
    "ohlc_ds.initializeSquenzing()\n",
    "\n",
    "train_ds, test_ds = ohlc_ds.split2train_test(0.25)\n",
    "print(f\"number of stocks, train stocks, test stocks: {len(ohlc_ds.stocks)}, {len(train_ds.stocks)}, {len(test_ds.stocks)}\")\n",
    "\n",
    "databunch = DataBunch(train_ds.dataloader(batch_size=2048*4, shuffle=True,  drop_last=True), \\\n",
    "                      test_ds.dataloader( batch_size=4096*2, shuffle=False, drop_last=False), \\\n",
    "                      c_in=4, c_out=4)\n",
    "\n",
    "#batch = next(iter(databunch.train_dl))\n",
    "#view = view_tfm(4,seq_length)\n",
    "#batch[0].dtype, batch[0].shape, view(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d7e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5330834, 5330834, 6843406, 6843406)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ohlc_ds.idx_seq), len(ohlc_ds), len(ohlc_ds.price_values), len(df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11520e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 1.27 s, total: 1min 12s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l = [len(b[0]) for b in databunch.train_dl]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3300403",
   "metadata": {},
   "source": [
    "CPU times: user 1min 16s, sys: 1.45 s, total: 1min 17s\n",
    "Wall time: 1min 17s\n",
    "CPU times: user 1min 13s, sys: 1.36 s, total: 1min 14s\n",
    "Wall time: 1min 14s\n",
    "CPU times: user 1min 10s, sys: 1.32 s, total: 1min 11s\n",
    "Wall time: 1min 11s\n",
    "CPU times: user 1min 14s, sys: 1.42 s, total: 1min 15s\n",
    "Wall time: 1min 15s\n",
    "CPU times: user 1min 11s, sys: 1.39 s, total: 1min 12s\n",
    "Wall time: 1min 12s\n",
    "CPU times: user 1min 17s, sys: 1.42 s, total: 1min 18s\n",
    "Wall time: 1min 18s\n",
    "CPU times: user 1min 19s, sys: 2.44 s, total: 1min 21s\n",
    "Wall time: 1min 21s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1386f9",
   "metadata": {},
   "source": [
    "# Statics on the mature stocks\n",
    " - min, max, mean, std, percentiles\n",
    " - calculate the normalization numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5274fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the following must be the same\n",
      "CPU times: user 681 ms, sys: 9.07 ms, total: 690 ms\n",
      "Wall time: 690 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5330834, 5328801)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the following must be the same\")\n",
    "%time stock_days = [len(ohlc_ds.stock_grps.get_group(stock)) for stock in ohlc_ds.stocks]\n",
    "len(ohlc_ds), sum(stock_days)-len(stock_days)*(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc405f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.452814e+06</td>\n",
       "      <td>5.452814e+06</td>\n",
       "      <td>5.452814e+06</td>\n",
       "      <td>5.452814e+06</td>\n",
       "      <td>5.452814e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.645078e+02</td>\n",
       "      <td>2.178618e-04</td>\n",
       "      <td>1.649711e-02</td>\n",
       "      <td>-1.613212e-02</td>\n",
       "      <td>5.501282e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.979344e+03</td>\n",
       "      <td>1.652678e-02</td>\n",
       "      <td>2.697750e-02</td>\n",
       "      <td>2.462773e-02</td>\n",
       "      <td>2.928071e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-4.800989e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02%</th>\n",
       "      <td>6.000000e-02</td>\n",
       "      <td>-2.137199e-01</td>\n",
       "      <td>-1.561031e-01</td>\n",
       "      <td>-3.292862e-01</td>\n",
       "      <td>-2.703173e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.520000e+01</td>\n",
       "      <td>-3.935865e-03</td>\n",
       "      <td>3.807107e-03</td>\n",
       "      <td>-2.225379e-02</td>\n",
       "      <td>-1.051304e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.957000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.079417e-02</td>\n",
       "      <td>-1.064184e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.393000e+01</td>\n",
       "      <td>4.559025e-03</td>\n",
       "      <td>2.192243e-02</td>\n",
       "      <td>-3.395201e-03</td>\n",
       "      <td>1.118881e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.98%</th>\n",
       "      <td>2.162699e+05</td>\n",
       "      <td>2.282198e-01</td>\n",
       "      <td>4.400000e-01</td>\n",
       "      <td>1.520392e-01</td>\n",
       "      <td>3.332735e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.449700e+05</td>\n",
       "      <td>1.407407e+00</td>\n",
       "      <td>1.477419e+00</td>\n",
       "      <td>1.210095e+00</td>\n",
       "      <td>1.421652e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_close          Open          High           Low         Close\n",
       "count     5.452814e+06  5.452814e+06  5.452814e+06  5.452814e+06  5.452814e+06\n",
       "mean      1.645078e+02  2.178618e-04  1.649711e-02 -1.613212e-02  5.501282e-04\n",
       "std       4.979344e+03  1.652678e-02  2.697750e-02  2.462773e-02  2.928071e-02\n",
       "min       2.000000e-02 -5.000000e-01 -4.800989e-01 -5.000000e-01 -5.000000e-01\n",
       "0.02%     6.000000e-02 -2.137199e-01 -1.561031e-01 -3.292862e-01 -2.703173e-01\n",
       "25%       1.520000e+01 -3.935865e-03  3.807107e-03 -2.225379e-02 -1.051304e-02\n",
       "50%       2.957000e+01  0.000000e+00  1.079417e-02 -1.064184e-02  0.000000e+00\n",
       "75%       5.393000e+01  4.559025e-03  2.192243e-02 -3.395201e-03  1.118881e-02\n",
       "99.98%    2.162699e+05  2.282198e-01  4.400000e-01  1.520392e-01  3.332735e-01\n",
       "max       3.449700e+05  1.407407e+00  1.477419e+00  1.210095e+00  1.421652e+00"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistics\n",
    "df_prices.loc[ohlc_ds.stocks,[PREV_CLOSE,OPEN,HIGH,LOW,CLOSE]].describe(percentiles=[0.0002, 0.25, 0.75, 0.9998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafbb1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_cnn_layers\n",
      "channels pr layers from input to output: [4, 64, 4]\n",
      "number of input and hidden layers: 1\n",
      "number of output layers :          3\n",
      "total number of layers:            4\n",
      "exception: {e}\n",
      "exception received 3\n",
      ":Traceback (most recent call last):\n",
      "  File \"/Users/kasparlund/code/AICodeData/ai/lib/learner/learner.py\", line 153, in one_batch\n",
      "    self.msn.notify(Stages.begin_batch,event)\n",
      "  File \"/Users/kasparlund/code/AICodeData/ai/lib/learner/learner.py\", line 68, in notify\n",
      "    f(event)\n",
      "  File \"/Users/kasparlund/code/AICodeData/ai/lib/learner/learner.py\", line 192, in begin_batch\n",
      "    def begin_batch(self, e:Event): e.learn.xb = self.tfm(e.learn.xb)\n",
      "  File \"/Users/kasparlund/code/AICodeData/ai/lib/learner/learner.py\", line 459, in _inner\n",
      "    def _inner(x): return x.view(*((-1,)+size))\n",
      "RuntimeError: shape '[-1, 4, 60]' is invalid for input of size 32768\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GetOneBatchCallback' object has no attribute 'xb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/code/AICodeData/ai/lib/model/modelmanager.py\u001b[0m in \u001b[0;36mgetFirstbatch\u001b[0;34m(self, databunch, normalization)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mcb\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_subcription_by_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGetOneBatchCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madapt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GetOneBatchCallback' object has no attribute 'xb'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setup model\n",
    "from lib.model.model import *\n",
    "\n",
    "from functools import partial\n",
    "#layers_sizes = [64,64,128,256]\n",
    "#layers_sizes = [128,64,32]\n",
    "layers_sizes = [64]\n",
    "layer = partial( conv_layer1, stride=1, bn=False, zero_bn=False, act=GeneralRelu, dropout_ratio=0.15 )\n",
    "mm    = CnnModelManager( get_cnn_model1(layers_sizes, databunch.c_in, databunch.c_out, layer ) )\n",
    "mm.initialize(is_resnet=False)\n",
    "\n",
    "tensor_input_view = view_tfm(4,seq_length)\n",
    "\n",
    "xb,_ = mm.getFirstbatch( databunch, normalization = tensor_input_view)\n",
    "print(f\"input shape:{xb.shape}\")\n",
    "mm.summary(xb, print_mod=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af07522",
   "metadata": {},
   "source": [
    "# We start by a regressionmodel that predict the next OHLC\n",
    " - First try will be the to minimize the squared sum of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c32866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def my_mse_loss(t_in, t_target): return (t_in-t_target).square().mean()\n",
    "\n",
    "sched        = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)]) \n",
    "cbfs         = [TrainableModelCallback, TrainEvalCallback, OptimizerCallback, \n",
    "#                partial(CudaCallback, device= torch.device('cuda',0)),\n",
    "#                partial(ParamScheduler, 'lr', sched),\n",
    "                partial(BatchTransformXCallback, tfm = tensor_input_view), \n",
    "#                partial(MixUp,Î±=0.4),\n",
    "#                LR_Finder,                \n",
    "                Recorder, \n",
    "#                partial(AvgStatsCallback,[accuracy]),\n",
    "#                partial(AvgStatsCallback,[my_mse_loss]),\n",
    "                partial(AvgStatsCallback,[torch.nn.functional.mse_loss]),\n",
    "#                partial(AvgStatsCallback,[torch.nn.functional.smooth_l1_loss]),\n",
    "                ProgressCallback\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5479f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception: {e}\n",
      "exception received 3\n",
      ":Traceback (most recent call last):\n",
      "  File \"/Users/kasparlund/code/AICodeData/ai/lib/learner/learner.py\", line 153, in one_batch\n",
      "    self.msn.notify(Stages.begin_batch,event)\n",
      "  File \"/Users/kasparlund/code/AICodeData/ai/lib/learner/learner.py\", line 68, in notify\n",
      "    f(event)\n",
      "  File \"/Users/kasparlund/code/AICodeData/ai/lib/learner/learner.py\", line 192, in begin_batch\n",
      "    def begin_batch(self, e:Event): e.learn.xb = self.tfm(e.learn.xb)\n",
      "  File \"/Users/kasparlund/code/AICodeData/ai/lib/learner/learner.py\", line 459, in _inner\n",
      "    def _inner(x): return x.view(*((-1,)+size))\n",
      "RuntimeError: shape '[-1, 4, 60]' is invalid for input of size 32768\n",
      "\n",
      "CPU times: user 1.45 s, sys: 59 ms, total: 1.51 s\n",
      "Wall time: 931 ms\n"
     ]
    }
   ],
   "source": [
    "opt       = SGD(sched,max_lr=0.25)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "#loss_func = torch.nn.SmoothL1Loss()\n",
    "#loss_func = my_mse_loss \n",
    "\n",
    "learn = Learner( mm.model, databunch, loss_func=loss_func)\n",
    "%time learn.fit(1, opt=opt, cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792fb0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bf618a160ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_subcription_by_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecorder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_subcription_by_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecorder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/AICodeData/ai/lib/learner/learner.py\u001b[0m in \u001b[0;36mplot_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'optimizers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.find_subcription_by_cls(Recorder).plot_lr(),plt.show()\n",
    "learn.find_subcription_by_cls(Recorder).plot_loss(skip_start=0),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#def predict(learn, price_sequences, tfm):\n",
    "#    with torch.no_grad():\n",
    "#        return learn.model( tfm(torch.tensor(price_sequences) ) )\n",
    "price_sequences, price_targets = ohlc_ds.getBatch(stocks=[\"ABMD\", \"AAPL\"])\n",
    "predictions    = mm.predict(price_sequences, tensor_input_view)\n",
    "\n",
    "(PREDICT_OPEN,PREDICT_HIGH,PREDICT_LOW,PREDICT_CLOSE) = [\"predict_\"+ name for name in [OPEN,HIGH,LOW,CLOSE]]\n",
    "for idx,name in enumerate([PREDICT_OPEN, PREDICT_HIGH, PREDICT_LOW, PREDICT_CLOSE]):\n",
    "    price_targets.insert(len(price_targets.columns), name, predictions[:,idx].numpy())\n",
    "price_targets[[OPEN,HIGH,LOW,CLOSE,PREDICT_OPEN,PREDICT_HIGH,PREDICT_LOW,PREDICT_CLOSE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963344b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "sqrt(0.000587), 0.01**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
