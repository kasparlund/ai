{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87513f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp finance.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b50821",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c8a9a1b",
   "metadata": {},
   "source": [
    "#add the parent directiry so that wecan access modules the and inits subdirectories\n",
    "import sys, os, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir  = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from lib.data.lists import *\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the main functionality from the SimFin Python API.\n",
    "import simfin as sf\n",
    "\n",
    "# Import names used for easy access to SimFin's data-columns.\n",
    "from simfin.names import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0b1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version of the SimFin Python API.\n",
    "sf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e732be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiateSimFin(key='free'):\n",
    "    # SimFin data-directory.\n",
    "    sf.set_data_dir('~/simfin_data/')\n",
    "    # SimFin load API key or use free data.\n",
    "    sf.load_api_key(path='~/simfin_api_key.txt', default_key=key)\n",
    "    return Path.home()/\"simfin_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "#   extrem_increase,extrem__decrease = [], 2.5, -.73\n",
    "#   extrem_increase,extrem__decrease = [], 1.5, -.5\n",
    "EXTREM_HL = \"extrem_hl\"\n",
    "def flagstocks_extrem_hl(df_prices, extrem_increase, extrem__decrease):\n",
    "    #remove mature stocks with \"nan\" prices\n",
    "    if EXTREM_HL in df_prices.columns:\n",
    "        df_prices.drop(labels=EXTREM_HL,axis=1,inplace=True)\n",
    "\n",
    "    gt_p = df_prices[[HIGH]].gt(extrem_increase)\n",
    "    gt_p.insert(0,\"lt\",df_prices[[LOW]].lt(extrem__decrease))\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1,EXTREM_HL,gt_p.any(axis=1))\n",
    "    return df_prices\n",
    "\n",
    "TOO_FEW_DAYS = \"too_few_days\"\n",
    "def flagstocks_too_few_trading_days(df_prices, minimum_tradingdays):\n",
    "    grp_res = df_prices.groupby([\"Ticker\"]).apply(lambda group: len(group) < minimum_tradingdays)\n",
    "    grp_res.name = TOO_FEW_DAYS\n",
    "    merged = df_prices[[SIMFIN_ID]].join(grp_res, on=TICKER)\n",
    "    if TOO_FEW_DAYS in df_prices.columns:\n",
    "        df_prices.drop(labels=TOO_FEW_DAYS,axis=1,inplace=True)\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1, TOO_FEW_DAYS, merged[TOO_FEW_DAYS].values)\n",
    "    return df_prices\n",
    "\n",
    "HAS_NAN_DAYS = \"has_nan_days\"\n",
    "def flagstocks_with_nan_days(df_prices):\n",
    "    grp_res = df_prices.groupby([\"Ticker\"]).apply(lambda group: group[[OPEN,LOW,HIGH,CLOSE]].isnull().values.any() )\n",
    "    grp_res.name = HAS_NAN_DAYS\n",
    "    merged = df_prices[[SIMFIN_ID]].join(grp_res, on=TICKER)\n",
    "    if HAS_NAN_DAYS in df_prices.columns:\n",
    "        df_prices.drop(labels=HAS_NAN_DAYS,axis=1,inplace=True)\n",
    "    df_prices.insert(df_prices.columns.get_loc(SIMFIN_ID)+1, HAS_NAN_DAYS, merged[HAS_NAN_DAYS].values)\n",
    "    return df_prices\n",
    "\n",
    "def findInValidStocks(df_prices):\n",
    "    flags  = [HAS_NAN_DAYS,TOO_FEW_DAYS,EXTREM_HL]\n",
    "    groups = df_prices.groupby([\"Ticker\"])\n",
    "    return np.array([name for (name,group) in groups if group[flags].any(axis=1).any()])\n",
    "\n",
    "def findValidStocks(df_prices):\n",
    "    flags  = [HAS_NAN_DAYS,TOO_FEW_DAYS,EXTREM_HL]\n",
    "    groups = df_prices.groupby([\"Ticker\"])\n",
    "    return np.array([name for (name,group) in groups if not group[flags].any(axis=1).any()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fead46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from lib.data.lists import *\n",
    "import torch\n",
    "from torch.tensor import *\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "class Data():\n",
    "    def __init__(self, df_prices):\n",
    "        self.df_prices = df_prices\n",
    "        self.np_prices = None\n",
    "        self.seq_len   = None\n",
    "        self.columns   = None  #training and test columns\n",
    "        #insert a row counter/index\n",
    "        #if \"idx\" not in self.df_prices.columns:\n",
    "        #    self.df_prices.insert(loc=0, column=\"idx\", value=np.arange(len(self.df_prices),dtype=int))\n",
    "        self.df_prices[\"idx\"] = np.arange(len(self.df_prices),dtype=int)\n",
    "\n",
    "    #set sequence length and columns used for training and test\n",
    "    def changeTraining(self,seq_len,columns):\n",
    "        self.seq_len = seq_len\n",
    "        self.columns = columns\n",
    "        \n",
    "        #point to the first predictabel sample in a stock. \n",
    "        #this sample is predicted using df_prices[:seq_len,columns]\n",
    "        ix_predict = np.arange(len(self.df_prices),dtype=int)        \n",
    "        for g,d in self.df_prices.groupby([\"Ticker\"]):\n",
    "            ix_predict[d.idx[:seq_len]] = -1\n",
    "        self.df_prices[\"ix_predict\"] = ix_predict\n",
    "        self.np_prices = self.df_prices[self.columns].to_numpy()\n",
    "\n",
    "    def getTensor(self, ix, r_mixin=0.0, r_ix=None):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "\n",
    "        prices = self.np_prices #readability and local pointer is faster if used multiple times\n",
    "        pi     = prices[ix - self.seq_len : ix ] \n",
    "        pt     = prices[ix, : ]   \n",
    "        if r_ix:\n",
    "            #mix with another sequence\n",
    "            ro  = 1 - r_mixin\n",
    "            pi  = pi*ro + r_mixin*prices[r_ix - self.seq_len : r_ix]\n",
    "            pt  = pt*ro + r_mixin*prices[r_ix,:]\n",
    "        return torch.tensor( pi ), torch.tensor( pt ) #, index\n",
    "    \"\"\"\n",
    "    def getTensor(self, ix, r_mixin=0.0, ix_r=None):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "\n",
    "        prices = self.np_prices #readability and local pointer is faster if used multiple times\n",
    "        ixb    = ix - self.seq_len\n",
    "        ixe    = ix+len(self.columns)\n",
    "        pi     = torch.tensor( prices[ixb:ix ] )\n",
    "        pt     = torch.tensor( prices[ ix,:]   )\n",
    "        if r_mixin > 0.0:\n",
    "            #mix with another sequence\n",
    "            ix  = ix_r\n",
    "            ixb = ix - self.seq_len\n",
    "            ixe = ix + len(self.columns)\n",
    "            ro  = 1 - r_mixin\n",
    "            #print(f\"ixb,ix,ixe: {ixb,ix,ixe}\")\n",
    "            pi  = pi.mul_(ro) + torch.tensor( prices[ixb:ix] ).mul_(r_mixin)\n",
    "            pt  = pt.mul_(ro) + torch.tensor( prices[ix,:]   ).mul_(r_mixin)\n",
    "            #pi  = pi*ro + torch.tensor( prices[ixb:ix] )*r_mixin\n",
    "            #pt  = pt*ro + torch.tensor( prices[ix,:]   )*r_mixin\n",
    "            #pi  = pi.mul_(ro).add_( torch.tensor( prices[ixb:ix] ).mul_(r_mixin) )\n",
    "            #pt  = pt.mul_(ro).add_( torch.tensor( prices[ix,:]   ).mul_(r_mixin) )\n",
    "        return pi, pt #, index\n",
    "        \"\"\"\n",
    "    def getSequenceIndex(self,stocks):\n",
    "        #idx_seq = self.df_prices.loc[stocks,\"ix_predict\"].to_numpy()\n",
    "        idx_seq = self.df_prices.ix_predict.loc[stocks].to_numpy()\n",
    "        idx_seq = idx_seq[idx_seq>=0]\n",
    "        return idx_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "923f9e51",
   "metadata": {},
   "source": [
    "df_prices = loadShareprices()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "771ecd4d",
   "metadata": {},
   "source": [
    "data     = Data(df_prices)\n",
    "seq_len  = 3\n",
    "columns  = [CLOSE,OPEN]\n",
    "data.changeTraining(seq_len,columns)\n",
    "#data.df_prices[:10], \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "499eab9f",
   "metadata": {},
   "source": [
    "%time d = data.getTensor(ix=3, r_mixin=0.5, r_ix=4)\n",
    "%timeit -r 100 d = data.getTensor(ix=3, r_mixin=0.5, r_ix=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea27f54",
   "metadata": {},
   "source": [
    "import random\n",
    "import numpy as np\n",
    "%timeit np.random.random_sample()*.5\n",
    "%timeit random.uniform(0, .5 )\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ca0d945",
   "metadata": {},
   "source": [
    "b=True\n",
    "f=0.0\n",
    "ix_r=None\n",
    "%timeit -r 10 if b : a=0\n",
    "%timeit -r 10 if f==0.0 : a=0\n",
    "%timeit -r 10 if ix_r is None: a=0\n",
    "%timeit -r 10 if ix_r: a=0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3bec807",
   "metadata": {},
   "source": [
    "before optimization\n",
    "CPU times: user 250 Âµs, sys: 32 Âµs, total: 282 Âµs\n",
    "Wall time: 271 Âµs\n",
    "13.5 Âµs Â± 553 ns per loop (mean Â± std. dev. of 100 runs, 100000 loops each)\n",
    "\n",
    "after optimization\n",
    "CPU times: user 199 Âµs, sys: 62 Âµs, total: 261 Âµs\n",
    "Wall time: 224 Âµs\n",
    "12.7 Âµs Â± 372 ns per loop (mean Â± std. dev. of 10 runs, 100000 loops each)\n",
    "\n",
    "med mixin og optimering\n",
    "CPU times: user 237 Âµs, sys: 59 Âµs, total: 296 Âµs\n",
    "Wall time: 261 Âµs\n",
    "23.2 Âµs Â± 873 ns per loop (mean Â± std. dev. of 100 runs, 10000 loops each)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1c402a9",
   "metadata": {},
   "source": [
    "        \n",
    "    \"\"\"\n",
    "    def getTensor(self, ix, r_mixin=0.0, ix_r=None):\n",
    "        #Notice that the dataset cannot be used for a RNN where the data should been returned from a sliding window\n",
    "\n",
    "        #Calculate the start and end of all sequences so that the dataloader can load and shuffle efficiently.\n",
    "        #add an index column to df_prices that we can used to calcualte start and end of sequences\n",
    "        if not \"idx\" in self.data.df_prices.columns:\n",
    "            self.data.df_prices.insert(loc=0, column=\"idx\", value=np.arange(len(self.df_prices),dtype=int))\n",
    "\n",
    "        #create one array \"prices with interleaved values from training.columns iinterleaved in\n",
    "        #fx if the require columns are \"open\", \"close\". Then prices contain row, columns values from\n",
    "        #df_price in the following order : open_row1, close_row1, open_row2, close_row2, ...\n",
    "        self.np_prices = np.empty(self.df_prices.shape[0]*len(self.column_names))\n",
    "        for (i,c) in enumerate(self.column_names):\n",
    "            self.np_prices[i::len(self.column_names)] = self.df_prices[c].values\n",
    "\n",
    "        self.idx_seq    = self.getSequenceIndexing(self.stocks)\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    def getSequenceIndexing(self):\n",
    "        #get an index to all valid samples in self.prices\n",
    "        idx_begin = [] #list of valid dataset index into the dataframe\n",
    "        stock_grps   = self.df_prices.groupby([\"Ticker\"])\n",
    "        for stock in stocks:\n",
    "            group = self.stock_grps.get_group(stock)\n",
    "            idx_begin.extend( group[\"idx\"].values[self.seq_length:len(group)] )\n",
    "        idx_begin    = np.array(idx_begin,dtype=int)\n",
    "        idx_seq      = np.empty( (len(idx_begin),2), dtype=int)\n",
    "        #idx_seq[:,0] = (idx_begin+self.seq_length)*len(self.column_names)\n",
    "        idx_seq[:,0] = idx_begin*len(self.column_names)\n",
    "        idx_seq[:,1] = idx_seq[:,0] - self.seq_length*len(self.column_names)\n",
    "        return idx_seq\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "        #get an index to all valid samples in self.prices\n",
    "        idx_begin = [] #list of valid dataset index into the dataframe\n",
    "        stock_grps   = self.df_prices.groupby([\"Ticker\"])\n",
    "        for stock in stocks:\n",
    "            group = self.stock_grps.get_group(stock)\n",
    "            idx_begin.extend( group[\"idx\"].values[self.seq_length:len(group)] )\n",
    "        idx_begin    = np.array(idx_begin,dtype=int)\n",
    "        idx_seq      = np.empty( (len(idx_begin),2), dtype=int)\n",
    "        #idx_seq[:,0] = (idx_begin+self.seq_length)*len(self.column_names)\n",
    "        idx_seq[:,0] = idx_begin*len(self.column_names)\n",
    "        idx_seq[:,1] = idx_seq[:,0] - self.seq_length*len(self.column_names)\n",
    "        return idx_seq\n",
    "        \n",
    "        \n",
    "        #get an index to all valid samples\n",
    "        idx_begin = [] #list of valid dataset index into the dataframe\n",
    "        for stock in self.stocks:\n",
    "            group = self.stock_grps.get_group(stock)\n",
    "            #idx_begin.extend( group[\"idx\"].values[:len(group)-self.seq_length] )\n",
    "            idx_begin.extend( group[\"idx\"].values[self.seq_length:len(group)] )\n",
    "        self.idx_seq = np.empty( (len(idx_begin),2), dtype=int)\n",
    "        self.idx_seq[:,0] = idx_begin\n",
    "        self.idx_seq[:,1] = self.idx_seq[:,0]-self.seq_length\n",
    "    \"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "#Create a dataset that uses all the stocks and daily prices\n",
    "#In order to save memory the df_prices is the same for both training and validation.\n",
    "#np_prices contains interleaved prices of the columns used for training/validation\n",
    "#fx if the require columns are \"open\", \"close\". Then np_prices contain row, columns values from\n",
    "#df_price in the following order : open_row1, close_row1, open_row2, close_row2, ...\n",
    "\n",
    "#for now self.np_prices are dublicated. Thus using more memory than needed.\n",
    "#Test and validation contain different stock taken drom the same df_prices\n",
    "\n",
    "#stocks    : are the stock tickers\n",
    "#stock_days: is the number of days pr stock. The number of days is in different for each stock\n",
    "#            The total number of samples is stock_days.sum()\n",
    "#batch_size: is the number of stocks in a batch\n",
    "#seq_length: is the number of stocks days in a batch.\n",
    "#the number of sample in the batch is seq_length*len(column_names)\n",
    "\n",
    "#As for now the dataset progress sequentially through the data during an epoch from a random offset.\n",
    "#Notice that there is no end of sequence-token to reset the model when the sequencen wraps around\n",
    "TRAIN_TEST   = \"train_test\"\n",
    "\n",
    "        \n",
    "class OHLCDataset(torch.utils.data.Dataset):\n",
    "    #x, y significes input vs output\n",
    "    def __init__(self, data, stocks, train_test=\"invalid\"):\n",
    "        self.data         = data #share data\n",
    "        self.stocks       = stocks\n",
    "\n",
    "        #Index to all start of sequences in the dataset\n",
    "        #The target is taken from the day after the sequence\n",
    "        self.idx_seq      = None\n",
    "        self.mixin        = 0.0  #ration to mix to sequences\n",
    "        self.train_test   = train_test        \n",
    "        self.idx_seq      = data.getSequenceIndex(stocks)\n",
    "        \n",
    "        \n",
    "    def changeAugmentation( self, mixing=0.5 ):\n",
    "        self.mixin = mixing\n",
    "        self.do_mix = self.mixin>0.0\n",
    "        self.ix_mix_queue = -1   \n",
    "        #self.idx_seq[random.randint(0, len(self)-1)] if self.mixin>0 else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_seq)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        ix = self.idx_seq[index]\n",
    "\n",
    "        #mix with another sequence\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.do_mix:\n",
    "            #performance optimization. It is much faste to generate many random numbers\n",
    "            #and make som book keeping \n",
    "            if self.ix_mix_queue==-1:\n",
    "                rng = np.random.default_rng()\n",
    "                self.rand_idx_seq   = rng.integers(0, len(self.idx_seq)-1,size=len(self.idx_seq))\n",
    "                #print(f\"self.rand_idx_seq.shape :{self.rand_idx_seq.shape}\\n{self.rand_idx_seq[:10]}\")\n",
    "                self.rand_fractions = rng.random(size=len(self.idx_seq))\n",
    "                #print(f\"self.rand_fractions.shape :{self.rand_fractions.shape}\\n{self.rand_fractions[:10]}\")\n",
    "                self.ix_mix_queue   = len(self.rand_idx_seq)-1\n",
    "\n",
    "            r_ix    = self.idx_seq[self.rand_idx_seq[self.ix_mix_queue]] # self.idx_seq[random.randint(0, len(self)-1)] if self.mixin>0 else None\n",
    "            r_mixin = self.rand_fractions[self.ix_mix_queue] #random.uniform(0, self.mixin )               if self.mixin>0 else 0.0\n",
    "            self.ix_mix_queue -= 1 \n",
    "            #print(f\"ix_mix_queue, r_ix,r_mixinÃ·{self.ix_mix_queue,r_ix,r_mixin}\")\n",
    "        else:\n",
    "            r_mixin=0.0\n",
    "            r_ix=None\n",
    "        \"\"\"\n",
    "            \n",
    "        r_ix    = self.idx_seq[random.randint(0, len(self)-1)] if self.do_mix else None\n",
    "        r_mixin = random.uniform(0, self.mixin )               if self.do_mix else 0.0\n",
    "            \n",
    "        return self.data.getTensor(ix=ix, r_mixin=r_mixin, r_ix=r_ix)\n",
    "\n",
    "    #stocks: stocks that you want the price_input and target for\n",
    "    def getBatch(self, stocks):\n",
    "        #pt: price target\n",
    "        #pi: price input\n",
    "        #extract the rows in df_proces containing the stocks in the batch\n",
    "        idx = self.getSequenceIndexing(stocks);\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        df_prices_selected = self.df_prices[ self.df_prices.index.get_level_values(0).isin(stocks) ]\n",
    "        stock_grps         = df_prices_selected.groupby([\"Ticker\"])\n",
    "        idx, seq_len = [], self.seq_length\n",
    "        for name,group in stock_grps:\n",
    "            idx.extend(group[\"idx\"].values[seq_len:len(group)])\n",
    "        idx = np.array(idx,dtype=int)\n",
    "\n",
    "        pt = self.df_prices.iloc[idx]\n",
    "        pi = [self.df_prices.iloc[ib:ie, self.ix_columns].values for ib,ie in zip(pt.idx - seq_len, pt.idx)]\n",
    "        return np.array(pi), self.df_prices.iloc[idx].copy()\n",
    "        \"\"\"\n",
    "\n",
    "    def dataloader(self, batch_size:int, shuffle:bool, num_workers:int=0, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(self, batch_size=batch_size, shuffle=shuffle,\n",
    "                                           num_workers=num_workers, drop_last=drop_last)\n",
    "\n",
    "    def split2train_test(self, test_percentage):\n",
    "        #split the stocks in train and test stocks\n",
    "        #It might be better to make a split in historical vs new prices\n",
    "        ix_all   = np.arange(len(self.stocks),dtype=int)\n",
    "        np.random.shuffle(ix_all)\n",
    "\n",
    "        nb_test  = int(round(test_percentage*len(self.stocks)))\n",
    "        ix_train = ix_all[nb_test:]\n",
    "        ix_test  = ix_all[:nb_test]\n",
    "        train_stocks = self.stocks[ix_train]\n",
    "        test_stocks  = self.stocks[ix_test]\n",
    "        self.data.df_prices[TRAIN_TEST]   = \"invalid\"\n",
    "        self.data.df_prices.loc[train_stocks,TRAIN_TEST] = \"train\"\n",
    "        self.data.df_prices.loc[test_stocks,TRAIN_TEST ] = \"test\"\n",
    "        return self.__class__(self.data, self.stocks[ix_train], \"train\"),\\\n",
    "               self.__class__(self.data, self.stocks[ix_test],  \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 Âµs, sys: 0 ns, total: 10 Âµs\n",
      "Wall time: 13.1 Âµs\n",
      "CPU times: user 6 Âµs, sys: 7 Âµs, total: 13 Âµs\n",
      "Wall time: 14.8 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3408799899928588"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4aba98a",
   "metadata": {},
   "source": [
    "#from numpy.random import default_rng\n",
    "len_idx =10\n",
    "rng = np.random.default_rng()\n",
    "ri=rand_idx_sequence = rng.integers(0, len_idx,size=len_idx)\n",
    "rf=rand_frations = rng.random(len_idx)\n",
    "print(ri)\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def loadShareprices():\n",
    "    #Load shareprices for testing and development\n",
    "    dataPath = initiateSimFin(key='free')\n",
    "    print(f\"dataPath:{dataPath} exists:{dataPath.exists()}\")\n",
    "\n",
    "    # Data for USA.\n",
    "    market = 'us'\n",
    "    # Daily Share-Prices.\n",
    "    return sf.load_shareprices(variant='daily', market=market)\n",
    "\n",
    "\n",
    "PREV_CLOSE = \"previous_close\"\n",
    "def alignPreviousClose(df_prices):\n",
    "    # Make a new column to show the closing price from the previous day on the same line as current day.\n",
    "    # This is done using the shift function for the dataserie\n",
    "    #\n",
    "    # Result: All stock and prices are listed in the same tabel. Therefore, the firat priceline of each stock vil now\n",
    "    # contain the close of the previous stock. For the first stock this value vil be \"nan\".\n",
    "    # These incoherent pricelines are removed in the nest step\n",
    "\n",
    "    #if PREV_CLOSE not in df_prices.columns:\n",
    "    if not PREV_CLOSE in df_prices.columns:\n",
    "        df_prices.insert(df_prices.columns.get_loc(OPEN), PREV_CLOSE, df_prices[CLOSE].shift(), allow_duplicates=False)\n",
    "\n",
    "    #identify the first stock in each stockgroup and the remove it\n",
    "    stock_name    = df_prices.index.get_level_values(0)\n",
    "    new_stock     = np.ones(len(df_prices), dtype=bool)\n",
    "    new_stock[1:] = stock_name[0:len(stock_name)-1] != stock_name[1:len(stock_name)]\n",
    "    df_prices.drop(df_prices.index[new_stock], axis=0, inplace=True)\n",
    "    return df_prices\n",
    "\n",
    "#extrem_increase,extrem__decrease = 2.5, -.73\n",
    "#extrem_increase,extrem__decrease = 1.5, -.5\n",
    "def procesSharePrices(df_prices, minimum_tradingdays=180, extrem_increase = 0.5, extrem__decrease = -0.5):\n",
    "\n",
    "    # load and identify valid data\n",
    "    df_prices = alignPreviousClose(df_prices)\n",
    "    df_prices = logMinusPreviousClose(df_prices)\n",
    "\n",
    "    flagstocks_extrem_hl(df_prices, extrem_increase, extrem__decrease)\n",
    "    flagstocks_too_few_trading_days(df_prices,minimum_tradingdays)\n",
    "    flagstocks_with_nan_days(df_prices)\n",
    "\n",
    "    validStocks, inValidStocks = findValidStocks(df_prices), findInValidStocks(df_prices)\n",
    "\n",
    "    stock_grps = df_prices.groupby([\"Ticker\"])\n",
    "    stocks     = np.array(list(stock_grps.groups))\n",
    "    sizes      = stock_grps.size()\n",
    "    print(f\"number of stocks:         {len(stocks)}\")\n",
    "    print(f\"number of valid stocks:   {len(validStocks)}\")\n",
    "    print(f\"number of invalid stocks: {len(inValidStocks)}\")\n",
    "\n",
    "    print(f\"smallest pricelines pr stock: {sizes.sort_values()[:5]}\")\n",
    "    print(f\"longest pricelines pr stock:  {sizes.sort_values()[-5:]}\")\n",
    "\n",
    "    return df_prices, stocks, validStocks, inValidStocks\n",
    "\n",
    "predict_prefix=\"predict_\"\n",
    "PREDICT_OPEN  = predict_prefix+OPEN\n",
    "PREDICT_HIGH  = predict_prefix+HIGH\n",
    "PREDICT_LOW   = predict_prefix+LOW\n",
    "PREDICT_CLOSE = predict_prefix+CLOSE\n",
    "\n",
    "def predict_stocks(dataset, modelmanager, stocks, tfm_input ):\n",
    "    price_sequences, price_targets = dataset.getBatch(stocks=stocks)\n",
    "    predictions    = modelmanager.predict(price_sequences, tfm_input)\n",
    "\n",
    "    # inser the preduction in price_targets\n",
    "    prediction_columns = [ predict_prefix + name for name in dataset.column_names ]\n",
    "    print(prediction_columns)\n",
    "    for idx,name in enumerate(prediction_columns):\n",
    "        print(idx, name)\n",
    "        if name in price_targets.columns :\n",
    "            price_targets.drop([name], axis='columns', inplace=True)\n",
    "        else:\n",
    "            price_targets.insert(len(price_targets.columns), name, predictions[:,idx-1].numpy())\n",
    "    return price_targets, prediction_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e87b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "#Convert OHLC to percentages of the previous days closing price\n",
    "#tahe the log onallprice action and subtract Previousclose from from price\n",
    "#to arrive at log percentage change relativ til previous close\n",
    "def logMinusPreviousClose(df_prices):\n",
    "    df_prices[[PREV_CLOSE,OPEN,CLOSE,LOW,HIGH]] = df_prices[[PREV_CLOSE,OPEN,CLOSE,LOW,HIGH]].apply(np.log)\n",
    "    df_prices[[OPEN,CLOSE,LOW,HIGH]]            = df_prices[[OPEN,CLOSE,LOW,HIGH]].sub(df_prices[PREV_CLOSE],axis=0)\n",
    "    return df_prices\n",
    "\n",
    "normalized_suffix=\"_normalized\"\n",
    "OPEN_NORM  = OPEN +normalized_suffix\n",
    "HIGH_NORM  = HIGH +normalized_suffix\n",
    "LOW_NORM   = LOW  +normalized_suffix\n",
    "CLOSE_NORM = CLOSE+normalized_suffix\n",
    "\n",
    "def normalizeData( df_prices, stats, normalized_suffix=normalized_suffix):\n",
    "    normalized_columns = []\n",
    "    for c in [OPEN,HIGH,LOW,CLOSE]:\n",
    "        mean,std = [stats.loc[\"mean\",c], stats.loc[\"std\",c]]\n",
    "        normalized_columns.append( c+normalized_suffix )\n",
    "        df_prices[c+normalized_suffix] = df_prices[c].div(std)\n",
    "    return df_prices,normalized_columns\n",
    "\n",
    "def truncateExtremes(df_prices,training_columns,stats, percent_min, percent_max):\n",
    "    for c in training_columns:\n",
    "        v_min,v_max = [stats.loc[percent_min,c], stats.loc[percent_max,c]]\n",
    "        ix = df_prices[c] < v_min\n",
    "        df_prices.loc[ix,c] = v_min\n",
    "        ix = df_prices[c] > v_max\n",
    "        df_prices.loc[ix,c] = v_max\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f814f0",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727c4a2",
   "metadata": {},
   "source": [
    "# Statics on the mature stocks\n",
    "min, max, mean, std, percentiles\n",
    "calculate the normalization numbers\n",
    "\n",
    "# Create dataset\n",
    "The dataset must a batch with number of stock = batch_size\n",
    "Each sequence of stockprice (ohlc) return from the dataset must be of the samme sequence_length During the training the network will process the sequence day by day\n",
    "\n",
    "At the beginning of each epoch It must be possible to shuffle the stock It must be possible to shuffle the start date of the stockprices for each stock\n",
    "\n",
    "The dataframe will remain fixed during the training using indirect indexing This will be faster and use less memory for large dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd4195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataPath:/Users/kasparlund/simfin_data exists:True\n",
      "Dataset \"us-shareprices-daily\" on disk (29 days old).\n",
      "- Loading from disk ... Done!\n",
      "CPU times: user 26.1 s, sys: 1.63 s, total: 27.7 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%time df_prices = loadShareprices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d5351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stocks:         2615\n",
      "number of valid stocks:   1626\n",
      "number of invalid stocks: 989\n",
      "smallest pricelines pr stock: Ticker\n",
      "NLN      1\n",
      "WMG      2\n",
      "SSI     17\n",
      "GAMZ    18\n",
      "PCP     24\n",
      "dtype: int64\n",
      "longest pricelines pr stock:  Ticker\n",
      "HTH    3379\n",
      "HT     3379\n",
      "HSY    3379\n",
      "HST    3379\n",
      "KBR    3379\n",
      "dtype: int64\n",
      "CPU times: user 54.7 s, sys: 3.01 s, total: 57.7 s\n",
      "Wall time: 57.9 s\n"
     ]
    }
   ],
   "source": [
    "%time df_prices, stocks, validStocks, inValidStocks = procesSharePrices(df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe7d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.354298e+06</td>\n",
       "      <td>4.354298e+06</td>\n",
       "      <td>4.354298e+06</td>\n",
       "      <td>4.354298e+06</td>\n",
       "      <td>4.354298e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.469855e+00</td>\n",
       "      <td>1.027393e-04</td>\n",
       "      <td>1.480531e-02</td>\n",
       "      <td>-1.525057e-02</td>\n",
       "      <td>2.008895e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.837691e-01</td>\n",
       "      <td>1.391626e-02</td>\n",
       "      <td>2.161822e-02</td>\n",
       "      <td>2.295876e-02</td>\n",
       "      <td>2.620453e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.912023e+00</td>\n",
       "      <td>-4.829644e-01</td>\n",
       "      <td>-4.327939e-01</td>\n",
       "      <td>-4.995624e-01</td>\n",
       "      <td>-4.867261e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02%</th>\n",
       "      <td>-3.912023e+00</td>\n",
       "      <td>-1.978955e-01</td>\n",
       "      <td>-1.431591e-01</td>\n",
       "      <td>-3.280761e-01</td>\n",
       "      <td>-2.681582e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>1.071584e+00</td>\n",
       "      <td>-3.971064e-02</td>\n",
       "      <td>-1.869213e-02</td>\n",
       "      <td>-1.013844e-01</td>\n",
       "      <td>-7.572054e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.888147e+00</td>\n",
       "      <td>-3.777153e-03</td>\n",
       "      <td>3.724399e-03</td>\n",
       "      <td>-2.094438e-02</td>\n",
       "      <td>-9.926187e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.492560e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.023463e-02</td>\n",
       "      <td>-1.012382e-02</td>\n",
       "      <td>2.614819e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.052307e+00</td>\n",
       "      <td>4.359616e-03</td>\n",
       "      <td>2.029475e-02</td>\n",
       "      <td>-3.302827e-03</td>\n",
       "      <td>1.068488e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>5.859361e+00</td>\n",
       "      <td>3.790040e-02</td>\n",
       "      <td>9.609670e-02</td>\n",
       "      <td>1.818721e-02</td>\n",
       "      <td>7.484441e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.98%</th>\n",
       "      <td>1.239616e+01</td>\n",
       "      <td>1.648063e-01</td>\n",
       "      <td>2.801563e-01</td>\n",
       "      <td>1.179797e-01</td>\n",
       "      <td>2.334339e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.275121e+01</td>\n",
       "      <td>4.894546e-01</td>\n",
       "      <td>4.985555e-01</td>\n",
       "      <td>4.795731e-01</td>\n",
       "      <td>4.818492e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        previous_close          Open          High           Low         Close\n",
       "count     4.354298e+06  4.354298e+06  4.354298e+06  4.354298e+06  4.354298e+06\n",
       "mean      3.469855e+00  1.027393e-04  1.480531e-02 -1.525057e-02  2.008895e-04\n",
       "std       9.837691e-01  1.391626e-02  2.161822e-02  2.295876e-02  2.620453e-02\n",
       "min      -3.912023e+00 -4.829644e-01 -4.327939e-01 -4.995624e-01 -4.867261e-01\n",
       "0.02%    -3.912023e+00 -1.978955e-01 -1.431591e-01 -3.280761e-01 -2.681582e-01\n",
       "1%        1.071584e+00 -3.971064e-02 -1.869213e-02 -1.013844e-01 -7.572054e-02\n",
       "25%       2.888147e+00 -3.777153e-03  3.724399e-03 -2.094438e-02 -9.926187e-03\n",
       "50%       3.492560e+00  0.000000e+00  1.023463e-02 -1.012382e-02  2.614819e-04\n",
       "75%       4.052307e+00  4.359616e-03  2.029475e-02 -3.302827e-03  1.068488e-02\n",
       "99%       5.859361e+00  3.790040e-02  9.609670e-02  1.818721e-02  7.484441e-02\n",
       "99.98%    1.239616e+01  1.648063e-01  2.801563e-01  1.179797e-01  2.334339e-01\n",
       "max       1.275121e+01  4.894546e-01  4.985555e-01  4.795731e-01  4.818492e-01"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistics on the mature stocks\n",
    "stats = df_prices.loc[validStocks,[PREV_CLOSE,OPEN,HIGH,LOW,CLOSE]].describe(percentiles=\\\n",
    "                                                                             [0.0002, 0.01, 0.25, 0.75, 0.99, 0.9998])        \n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e7b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage =>0: 52.569759809732815\n",
      "percentage ==0: 2.273041486825201\n",
      "percentage  <0: 47.430240190267185\n",
      "mean=0 percentage =>0: 50.13044582616991\n",
      "mean=0 percentage ==0: 0.0\n",
      "mean=0 percentage  <0: 49.86955417383009\n",
      "CPU times: user 354 ms, sys: 114 ms, total: 468 ms\n",
      "Wall time: 470 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_valid =df_prices.loc[validStocks]\n",
    "print( f\"percentage =>0: {df_valid[CLOSE].ge(0).sum()/len(df_valid)*100}\")\n",
    "print( f\"percentage ==0: {df_valid[CLOSE].eq(0).sum()/len(df_valid)*100}\")\n",
    "print( f\"percentage  <0: {df_valid[CLOSE].lt(0).sum()/len(df_valid)*100}\")\n",
    "\n",
    "print( f\"mean=0 percentage =>0: {(df_valid[CLOSE]-stats.loc['mean',CLOSE]).ge(0).sum()/len(df_valid)*100}\")\n",
    "print( f\"mean=0 percentage ==0: {(df_valid[CLOSE]-stats.loc['mean',CLOSE]).eq(0).sum()/len(df_valid)*100}\")\n",
    "print( f\"mean=0 percentage  <0: {(df_valid[CLOSE]-stats.loc['mean',CLOSE]).lt(0).sum()/len(df_valid)*100}\")\n",
    "del df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcae053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.98 s, sys: 1.21 s, total: 5.19 s\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from lib.learner.learner import*\n",
    "from lib.learner.optimizers import*\n",
    "from lib.model.model import*\n",
    "from lib.model.modelmanager import*\n",
    "import torch.nn as nn\n",
    "\n",
    "training_columns = [CLOSE,OPEN]\n",
    "#mean is so close to zero so we only devide by std\n",
    "stats = df_prices.loc[validStocks].describe(percentiles=[0.0002, 0.01, 0.25, 0.75, 0.99, 0.9998])\n",
    "df_prices, normalized_columns = normalizeData(df_prices,stats)\n",
    "\n",
    "#truncate extrems\n",
    "stats = df_prices.loc[validStocks,normalized_columns].describe(percentiles=[0.0002, 0.01, 0.25, 0.75, 0.99, 0.9998])\n",
    "df_prices = truncateExtremes(df_prices,normalized_columns, stats, \"1%\", \"99%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabc053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_length: 360 training columns = ['Close_normalized', 'Open_normalized']\n"
     ]
    }
   ],
   "source": [
    "seq_length = 360\n",
    "training_columns = [CLOSE_NORM,OPEN_NORM]\n",
    "print(f\"seq_length: {seq_length} training columns = {training_columns}\")\n",
    "\n",
    "data = Data(df_prices)\n",
    "data.changeTraining(seq_length,training_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stocks, train stocks, test stocks: 1626, 1220, 406\n",
      "CPU times: user 830 ms, sys: 125 ms, total: 955 ms\n",
      "Wall time: 958 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ohlc_ds = OHLCDataset(data, stocks=validStocks)\n",
    "train_ds, test_ds = ohlc_ds.split2train_test(0.25)\n",
    "train_ds.changeAugmentation( mixing=0.5 )\n",
    "\n",
    "print(f\"number of stocks, train stocks, test stocks: {len(ohlc_ds.stocks)}, {len(train_ds.stocks)}, {len(test_ds.stocks)}\")\n",
    "\n",
    "databunch = DataBunch(train_ds.dataloader(batch_size=2048, shuffle=True,  drop_last=True), \\\n",
    "                      test_ds.dataloader( batch_size=4096, shuffle=False, drop_last=False), \\\n",
    "                      c_in=len(ohlc_ds.data.columns), c_out=len(ohlc_ds.data.columns))\n",
    "\n",
    "#print(\"the following lengths must be the same\")\n",
    "#%time stock_days = [len(ohlc_ds.stock_grps.get_group(stock)) for stock in ohlc_ds.stocks]\n",
    "#print(len(ohlc_ds), sum(stock_days)-len(stock_days)*(seq_length+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time l = [len(b[0]) for b in databunch.train_dl]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c13f73bc",
   "metadata": {},
   "source": [
    "CPU times: user 1min 52s, sys: 2.09 s, total: 1min 54s\n",
    "Wall time: 1min 54s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d13be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>ix_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZYXI</th>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>6843401</td>\n",
       "      <td>6843401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-02</th>\n",
       "      <td>6843402</td>\n",
       "      <td>6843402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-03</th>\n",
       "      <td>6843403</td>\n",
       "      <td>6843403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>6843404</td>\n",
       "      <td>6843404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-05</th>\n",
       "      <td>6843405</td>\n",
       "      <td>6843405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       idx  ix_predict\n",
       "Ticker Date                           \n",
       "ZYXI   2020-06-01  6843401     6843401\n",
       "       2020-06-02  6843402     6843402\n",
       "       2020-06-03  6843403     6843403\n",
       "       2020-06-04  6843404     6843404\n",
       "       2020-06-05  6843405     6843405"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices[[\"idx\",\"ix_predict\"]].tail()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43fae38e",
   "metadata": {},
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
