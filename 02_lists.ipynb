{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic list class\n",
    "\n",
    "> List classes and Transform used extensively in the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation is here: https://kasparlund.github.io/ai_pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from collections.abc import *\n",
    "\n",
    "class ListContainer():\n",
    "    def __init__(self, items): self.items = items\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, (int,slice)): return self.items[idx]\n",
    "        if isinstance(idx[0],bool):\n",
    "            assert len(idx)==len(self) # bool mask\n",
    "            return [o for m,o in zip(idx,self.items) if m]\n",
    "        return [self.items[i] for i in idx]\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return iter(self.items)\n",
    "    def __setitem__(self, i, o): self.items[i] = o\n",
    "    def __delitem__(self, i): del(self.items[i])\n",
    "    def __repr__(self):\n",
    "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
    "        if len(self)>10: res = res[:-1]+ '...]'\n",
    "        return res\n",
    "    \n",
    "    def new(self, items): return self.__class__(items)\n",
    "    \n",
    "    def unique(self): return set(self)\n",
    "\n",
    "    def split2ways(self,selector):\n",
    "        true_list  = [i for i,s in zip(self,selector) if s]\n",
    "        false_list = [i for i,s in zip(self,selector) if not s]\n",
    "        return self.new(true_list), self.new(false_list)\n",
    "    \n",
    "    # parent labels use lambda path: path.parent.name\n",
    "    # grandparent labels use lambda path: path.parent.parent.name\n",
    "    def label_by_func(self, f, clsReturned=None): \n",
    "        cls = ListContainer if clsReturned==None else clsReturned\n",
    "        return cls([f(o) for o in self])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]\n",
    "\n",
    "def setify(o): return o if isinstance(o,set) else set(listify(o))\n",
    "\n",
    "from collections import OrderedDict\n",
    "def uniqueify(x, sort=False):\n",
    "    res = list(OrderedDict.fromkeys(x).keys())\n",
    "    if sort: res.sort()\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import random\n",
    "\n",
    "#basic structure that are referencede many places\n",
    "class Transform:\n",
    "    #applies a transform to source\n",
    "    def __call__( self, source ): return source\n",
    "\n",
    "class Transforms(Transform):\n",
    "    #provide the transforms as a list\n",
    "    def __init__( self, transforms, shuffle=False):\n",
    "        self.transforms, self.shuffle = listify(transforms), shuffle\n",
    "        \n",
    "    #applies a transform to source\n",
    "    def __call__( self, source ):\n",
    "        if self.shuffle : \n",
    "            random.shuffle(self.transforms)\n",
    "        for tfm in self.transforms:\n",
    "            source = tfm( source )\n",
    "        return source\n",
    "\n",
    "class DataBunch():\n",
    "    def __init__(self, train_dl, valid_dl, c_in, c_out):\n",
    "        self.train_dl,self.valid_dl,self.c_in,self.c_out = train_dl,valid_dl,c_in,c_out\n",
    "\n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "\n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset\n",
    "\n",
    "class Callback():\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from pathlib import Path\n",
    "\n",
    "\"\"\"\n",
    "We use the `ListContainer` to store our objects in an `ItemList`. \n",
    "The `get` method will need to be subclassed to explain how to access an element \n",
    "(open an image for instance), then the private `_get` method can allow us to apply any \n",
    "additional transform to it.\n",
    "`new` will be used in conjunction with `__getitem__` (that works for one index or a list of indices) \n",
    "to create training and validation set from a single stream when we split the data.\n",
    "\n",
    "Transforms only need to be functions that take an element of the ItemList and transform it. \n",
    "If they need state, they can be defined as a class. Also, having them as a class allows \n",
    "to define an _order attribute (default 0) that is used to sort the transforms.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class ItemList(ListContainer):\n",
    "    def __init__(self, items, path='.', tfm=Transform()):\n",
    "        super().__init__(items)\n",
    "        self.path, self.tfm = Path(path), tfm\n",
    "\n",
    "    def __repr__(self): return f'{super().__repr__()}\\nPath: {self.path}'\n",
    "    def new(self, items): return self.__class__(items, self.path, self.tfm)\n",
    "\n",
    "    def  get(self, i): return i\n",
    "    def _get(self, i): return self.tfm( self.get(i) )\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        res = super().__getitem__(idx)\n",
    "        if isinstance(res,list): return [self._get(o) for o in res]\n",
    "        else:                    return self._get(res)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "class FileList(ItemList):\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_files(p, fs, extensions=None):\n",
    "        p = Path(p)\n",
    "        res = [p/f for f in fs if not f.startswith('.')\n",
    "               and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "        return res\n",
    "                \n",
    "    @staticmethod\n",
    "    def get_files(path, extensions=None, recurse=False, include=None):\n",
    "        path       = Path(path)\n",
    "        extensions = setify(extensions)\n",
    "        extensions = {e.lower() for e in extensions}\n",
    "        if recurse:\n",
    "            res = []\n",
    "            for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "                if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
    "                else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
    "                res += FileList._get_files(p, f, extensions)\n",
    "            return res\n",
    "        else:\n",
    "            f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "            return FileList._get_files(path, f, extensions)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, path, extensions, recurse=True, include=None, tfm=Transform()):\n",
    "        files = FileList.get_files(path, extensions, recurse=recurse, include=include)\n",
    "        return cls(files, path=path, tfm=tfm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb files: 70000 nb labels: 70000 nb b_idx_training: 70000 unique labels:10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/kasparlund/.fastai/data/mnist_png/training/9/36655.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.core import *\n",
    "\n",
    "import mimetypes\n",
    "import numpy as np\n",
    "import json\n",
    "from lib.data.external import *\n",
    "path = untar_data(URLs.MNIST)\n",
    "\n",
    "imageExtensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))\n",
    "files  = FileList.from_files( path, imageExtensions )\n",
    "labels = files.label_by_func( lambda path: path.parent.name )\n",
    "ibx_training = files.label_by_func( lambda path: path.parent.parent.name==\"training\" )\n",
    "\n",
    "print( f\"nb files: {len(files)} nb labels: {len(labels)} nb b_idx_training: {len(ibx_training)}\"\\\n",
    "       +f\" unique labels:{len(labels.unique())}\" )\n",
    "\n",
    "sum(ibx_training)\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.FileList, __main__.FileList, __main__.FileList, 70000, 60000, 10000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test = files.split2ways(ibx_training)\n",
    "type(files), type(train), type(test), len(files), len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00_test.ipynb.\n",
      "Converted 01_data.external.ipynb.\n",
      "Converted 02_lists.ipynb.\n",
      "Converted 03_images-back 31-juni-2021.ipynb.\n",
      "Converted 03_images.ipynb.\n",
      "Converted 04_databunchs_undone.ipynb.\n",
      "Converted 05_Learner.ipynb.\n",
      "Converted 05_model.ipynb.\n",
      "Converted 06_modelmanger.ipynb.\n",
      "Converted 07_optimizers.ipynb.\n",
      "Converted app_image_01_imagenette_optimizers.ipynb.\n",
      "Converted app_image_01_mnist_optimizers.ipynb.\n",
      "Converted augmentation_cpu.ipynb.\n",
      "Converted data_block.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted mnist_experiments.ipynb.\n",
      "Converted mnist_initi_batchnorm.ipynb.\n",
      "Converted transfer_learning.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
