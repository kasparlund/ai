{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fec79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "at = [ torch.zeros(10) for i in range(5) ]\n",
    "#print(at)\n",
    "\n",
    "def forward(a):\n",
    "    print(a)\n",
    "    #q.get()#1+1\n",
    "    #q.put( q.get()+2 )\n",
    "\n",
    "# NOTE: this is required for the ``fork`` method to work\n",
    "if __name__ == '__main__':\n",
    "    processes = []\n",
    "    queues = []\n",
    "    #x = torch.zeros_like(a[0])\n",
    "    #x.share_memory()\n",
    "    for a in at:\n",
    "        q = mp.Queue(a)\n",
    "        p = mp.Process(target=forward, args=(q))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    #print(args)\n",
    "    #print(x)\n",
    "    #for q in queues:\n",
    "    #   print(q.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import torch\n",
    "\n",
    "done = mp.Event()\n",
    "\n",
    "def extractor_worker(done_queue):\n",
    "    done_queue.put(torch.Tensor(10,10))\n",
    "    done_queue.put(None)\n",
    "    done.wait()\n",
    "\n",
    "producers = []\n",
    "done_queue = mp.Queue()\n",
    "for i in range(0, 1):\n",
    "    process = mp.Process(target=extractor_worker,\n",
    "                         args=(done_queue,))\n",
    "    process.start()\n",
    "    producers.append(process)\n",
    "\n",
    "    for p in producers:\n",
    "        p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6166cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def target(inputs, outputs):\n",
    "    x = inputs.get()\n",
    "    outputs.put(x)\n",
    "    outputs.join()\n",
    "\n",
    "inputs = mp.Queue(1)\n",
    "outputs = mp.JoinableQueue(1)\n",
    "\n",
    "value = torch.tensor([1., 2.])\n",
    "\n",
    "inputs.put(value)\n",
    "proc = mp.Process(target=target, args=(inputs, outputs))\n",
    "proc.start()\n",
    "x = outputs.get()\n",
    "outputs.task_done()\n",
    "proc.join()\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07834677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.Tensor(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim,out_dim=720,300\n",
    "conv1d, linear = nn.Conv1d(in_dim, out_dim, 1), nn.Linear(in_dim, out_dim)\n",
    "\n",
    "# same input tensor\n",
    "tensor = torch.randn(2048,1, in_dim)\n",
    "permuted_tensor = tensor.permute(0, 2, 1).clone().contiguous()\n",
    "\n",
    "%time out_linear = linear(tensor)  # torch.Size([128, 256, 32])\n",
    "%time out_conv1d = conv1d(permuted_tensor)  # torch.Size([128, 32, 256])\n",
    "out_linear.shape,out_conv1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timeit, matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    \"\"\"Count the number of parameters in a module.\"\"\"\n",
    "    return sum([p.numel() for p in model.parameters()])\n",
    "\n",
    "\n",
    "def compare_params(linear, conv1d):\n",
    "    \"\"\"Compare whether two modules have identical parameters.\"\"\"\n",
    "    return (linear.weight.detach().numpy() == conv1d.weight.detach().numpy().squeeze()).all() and \\\n",
    "           (linear.bias.detach().numpy() == conv1d.bias.detach().numpy()).all()\n",
    "\n",
    "\n",
    "def compare_tensors(out_linear, out_conv1d):\n",
    "    \"\"\"Compare whether two tensors are identical.\"\"\"\n",
    "    return (out_linear.detach().numpy() == out_conv1d.permute(0, 2, 1).detach().numpy()).all()\n",
    "conv1d, linear = nn.Conv1d(8, 32, 1), nn.Linear(8, 32)\n",
    "\n",
    "# same input tensor\n",
    "tensor = torch.randn(128, 256, 8)\n",
    "permuted_tensor = tensor.permute(0, 2, 1).clone().contiguous()\n",
    "\n",
    "# same weights and bias\n",
    "linear.weight = nn.Parameter(conv1d.weight.squeeze(2))\n",
    "linear.bias = nn.Parameter(conv1d.bias)\n",
    "print(compare_params(linear, conv1d))  # True\n",
    "\n",
    "# check on the forward tensor\n",
    "out_linear = linear(tensor)  # torch.Size([128, 256, 32])\n",
    "out_conv1d = conv1d(permuted_tensor)  # torch.Size([128, 32, 256])\n",
    "print(compare_tensors(out_linear, out_conv1d))  # False\n",
    "plt.hist((out_linear.detach().numpy() - out_conv1d.permute(0, 2, 1).detach().numpy()).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randn(out_linear.shape)\n",
    "permuted_target = target.permute(0, 2, 1).clone().contiguous()\n",
    "\n",
    "loss_linear = nn.MSELoss()(target, out_linear)\n",
    "loss_linear.backward()\n",
    "loss_conv1d = nn.MSELoss()(permuted_target, out_conv1d)\n",
    "loss_conv1d.backward()\n",
    "\n",
    "plt.hist((linear.weight.grad.detach().numpy() - \n",
    "    conv1d.weight.grad.permute(0, 2, 1).detach().numpy()).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125dc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test execution speed on CPUs\n",
    "print(timeit.timeit(\"_ = linear(tensor)\", number=10000, setup=\"from __main__ import tensor, linear\"))\n",
    "print(timeit.timeit(\"_ = conv1d(permuted_tensor)\", number=10000, setup=\"from __main__ import conv1d, permuted_tensor\"))\n",
    "\n",
    "# change everything in *.cuda(), then test speed on GPUs\n",
    "%time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape,permuted_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c95ca",
   "metadata": {},
   "source": [
    "# multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocess import Pool\n",
    "COUNT = 10000000\n",
    "start = time.perf_counter()\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "\n",
    "pool = Pool(processes=2)\n",
    "start = time.perf_counter()\n",
    "r1 = pool.apply_async(countdown, [COUNT//2])\n",
    "r2 = pool.apply_async(countdown, [COUNT//2])\n",
    "pool.close()\n",
    "pool.join()\n",
    "print('Time used:', time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Process,Pool,Queue\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(q):\n",
    "    q.put('hello world')\n",
    "    \n",
    "def other_function():\n",
    "    q = Queue()\n",
    "    p = Process(target=f, args=[q])\n",
    "    p.start()\n",
    "    print (q.get())\n",
    "    p.join()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    other_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c34454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized x :\n",
      "tensor([[0.1303, 0.7657, 0.5110],\n",
      "        [0.4032, 0.0724, 0.8736]])\n",
      "\n",
      "tensor([[0.1303, 0.7657, 0.5110],\n",
      "        [0.4032, 0.0724, 0.8736]])\n",
      "tensor([[0.1303, 0.7657, 0.5110],\n",
      "        [0.4032, 0.0724, 0.8736]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "#import multiprocess as mp\n",
    "\n",
    "import lib.finance.train_extern_functions as extern\n",
    "from lib.finance.train_extern_functions import*\n",
    "\"\"\"\n",
    "#def ex_forward(m:nn.Module,queue:mp.Queue):\n",
    "def ex_forward(model,queue):\n",
    "    #t = queue.get()*2\n",
    "    #queue.put(t)\n",
    "    #queue.put(\"hello world\")\n",
    "    queue.put(f\"hello world:\\n{model(queue.get())}\")\n",
    "    #queue.put( 2+queue.get() )\n",
    "\"\"\"\n",
    "\n",
    "def f(q):\n",
    "   #q.put('hello world')\n",
    "    \n",
    "    q.put(f'hello world:\\n{q.get()}')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,dim1,dim2):\n",
    "        super().__init__()\n",
    "        self.l = nn.Linear(dim1,dim2)\n",
    "    def forward(self,x):\n",
    "        return self.l(x)\n",
    "    \n",
    "def other_function():\n",
    "    dim1,dim2=3,2\n",
    "    x = torch.rand(dim2,dim1)\n",
    "    print(f\"initialized x :\\n{x}\\n\")\n",
    "    stems = [Model(dim1,dim2),Model(dim1,dim2)]\n",
    "    processes = []\n",
    "    queues =[]\n",
    "    for s in stems:\n",
    "        s.share_memory()\n",
    "        q = mp.Queue()\n",
    "        queues.append(q)\n",
    "        q.put(x)\n",
    "        p = mp.Process(target=extern.ex_forward, args=[s,q])\n",
    "        #p = mp.Process(target=f, args=[q])\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        \n",
    "    #x_stem = queues[0].get()\n",
    "    for q in queues: #[1:]:\n",
    "        if not q.empty():\n",
    "            print(q.get())\n",
    "        #x_stem = x_stem + q.get()\n",
    "    #print(f\"processed x :{x_stem}\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    #mp.set_start_method(\"fork\")\n",
    "    other_function()    \n",
    "#dim1,dim2=3,2\n",
    "#model = Model(3,2)\n",
    "#x = torch.rand(dim2,dim1)\n",
    "#model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from model import MyModel\n",
    "\n",
    "def train(model):\n",
    "    # Construct data_loader, optimizer, etc.\n",
    "    for data, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss_fn(model(data), labels).backward()\n",
    "        optimizer.step()  # This will update the shared parameters\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_processes = 4\n",
    "    model = MyModel()\n",
    "    # NOTE: this is required for the ``fork`` method to work\n",
    "    model.share_memory()\n",
    "    processes = []\n",
    "    for rank in range(num_processes):\n",
    "        p = mp.Process(target=train, args=(model,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855cf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "CPU times: user 11.9 ms, sys: 4.43 ms, total: 16.4 ms\n",
      "Wall time: 13.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([761300, 996091, 133378, ..., 927159, 111212, 303312])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "n=int(1e6)\n",
    "print(n)\n",
    "%time np.random.uniform(low=0, high=1, size=n)\n",
    "r_indices = np.random.randint(0,n, n)\n",
    "r_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e417b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
